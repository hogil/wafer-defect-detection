#!/usr/bin/env python3
"""
ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ ìƒíƒœ í…ŒìŠ¤íŠ¸
"""

import torch
import timm
from pathlib import Path
from config import ConfigManager

def test_pretrained_loading():
    """ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ í…ŒìŠ¤íŠ¸"""
    
    print("ğŸ§ª Testing pretrained weight loading...")
    
    # ì„¤ì • ë¡œë“œ
    config_manager = ConfigManager()
    config = config_manager.get_config()
    
    # ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
    pretrained_path = Path(config.CONVNEXT_PRETRAINED_MODEL)
    pretrained_weights = torch.load(pretrained_path, map_location='cpu')
    
    # model. prefix ì œê±°
    clean_pretrained_weights = {}
    for key, value in pretrained_weights.items():
        if key.startswith('model.'):
            new_key = key[6:]  # "model." ì œê±°
            clean_pretrained_weights[new_key] = value
        else:
            clean_pretrained_weights[key] = value
    
    # ê°€ì¤‘ì¹˜ì—ì„œ í´ë˜ìŠ¤ ìˆ˜ ì¶”ì¶œ
    weight_num_classes = None
    for key in clean_pretrained_weights.keys():
        if key in ['head.fc.weight', 'classifier.weight']:
            weight_num_classes = clean_pretrained_weights[key].shape[0]
            break
    
    # ëª¨ë¸ ìƒì„± (ê°€ì¤‘ì¹˜ì˜ í´ë˜ìŠ¤ ìˆ˜ë¡œ)
    print(f"ğŸ¤– Creating model: {config.CONVNEXT_MODEL_NAME}")
    model = timm.create_model(
        config.CONVNEXT_MODEL_NAME,
        pretrained=False,
        num_classes=weight_num_classes
    )
    
    # ë¶„ë¥˜ í—¤ë“œë¥¼ í…ŒìŠ¤íŠ¸ìš© í´ë˜ìŠ¤ ìˆ˜ë¡œ êµì²´
    if weight_num_classes != 4:
        # ê¸°ì¡´ ë¶„ë¥˜ í—¤ë“œ ì œê±°
        if hasattr(model, 'head'):
            delattr(model, 'head')
        if hasattr(model, 'classifier'):
            delattr(model, 'classifier')
        
        # ìƒˆë¡œìš´ ë¶„ë¥˜ í—¤ë“œ ì¶”ê°€
        if hasattr(model, 'head'):
            model.head = torch.nn.Linear(model.head.in_features, 4)
        elif hasattr(model, 'classifier'):
            model.classifier = torch.nn.Linear(model.classifier.in_features, 4)
        else:
            # ConvNeXtV2ì˜ ê²½ìš° head.fcë¥¼ ì§ì ‘ ìˆ˜ì •
            if hasattr(model, 'head') and hasattr(model.head, 'fc'):
                model.head.fc = torch.nn.Linear(model.head.fc.in_features, 4)
    
    # ê°€ì¤‘ì¹˜ ë¡œë“œ (ë¶„ë¥˜ í—¤ë“œ ì œì™¸)
    model_dict = model.state_dict()
    pretrained_dict = {k: v for k, v in clean_pretrained_weights.items() 
                      if k in model_dict and 'head' not in k and 'classifier' not in k}
    
    model_dict.update(pretrained_dict)
    model.load_state_dict(model_dict, strict=True)
    
    print(f"âœ… Model created:")
    print(f"  - Architecture: {config.CONVNEXT_MODEL_NAME}")
    print(f"  - Weight classes: {weight_num_classes}")
    print(f"  - Test classes: 4")
    print(f"  - Image size: {config.CLASSIFICATION_SIZE}")
    print(f"  - Pretrained: Yes ({len(pretrained_dict)} layers)")
    
    return True

if __name__ == "__main__":
    test_pretrained_loading() 