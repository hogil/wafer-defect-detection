#!/usr/bin/env python3
"""
ğŸ¯ GradCAM Utils - ê°„ë‹¨í•˜ê³  ì•ˆì •ì ì¸ GradCAM êµ¬í˜„
"""

import logging
from typing import Optional, Tuple

import torch
import torch.nn.functional as F
import numpy as np

logger = logging.getLogger(__name__)


class GradCAMError(Exception):
    """GradCAM ê´€ë ¨ ì˜ˆì™¸"""
    pass


class GradCAMAnalyzer:
    """
    ê°„ë‹¨í•˜ê³  ì•ˆì •ì ì¸ GradCAM ë¶„ì„ê¸°
    ConvNeXtV2 ëª¨ë¸ì— ìµœì í™”ë¨
    """
    
    def __init__(self, model: torch.nn.Module, target_layer_name: str = "stages.3"):
        """
        ì´ˆê¸°í™”
        
        Args:
            model: íƒ€ê²Ÿ ëª¨ë¸
            target_layer_name: íƒ€ê²Ÿ ë ˆì´ì–´ ì´ë¦„ (ì ìœ¼ë¡œ êµ¬ë¶„ëœ ê²½ë¡œ)
            
        Raises:
            GradCAMError: ì´ˆê¸°í™” ì‹¤íŒ¨ì‹œ
        """
        self.model = model
        self.gradients = None
        self.activations = None
        self.target_layer_name = target_layer_name
        
        try:
            # íƒ€ê²Ÿ ë ˆì´ì–´ ì°¾ê¸°
            layer = model
            for name in target_layer_name.split('.'):
                if not hasattr(layer, name):
                    raise GradCAMError(f"Layer '{name}' not found in model")
                layer = getattr(layer, name)
            
            self.target_layer = layer
            
            # Hook ë“±ë¡
            self.forward_hook = layer.register_forward_hook(self._forward_hook)
            self.backward_hook = layer.register_full_backward_hook(self._backward_hook)
            
            logger.info(f"GradCAM initialized for layer: {target_layer_name}")
            
        except Exception as e:
            raise GradCAMError(f"Failed to initialize GradCAM: {str(e)}")
    
    def _forward_hook(self, module, input, output):
        """Forward hook - activation ì €ì¥"""
        self.activations = output
    
    def _backward_hook(self, module, grad_input, grad_output):
        """Backward hook - gradient ì €ì¥"""
        self.gradients = grad_output[0]
    
    def generate_gradcam(
        self, 
        input_tensor: torch.Tensor, 
        target_class: Optional[int] = None
    ) -> np.ndarray:
        """
        GradCAM ìƒì„±
        
        Args:
            input_tensor: ì…ë ¥ í…ì„œ (B, C, H, W)
            target_class: íƒ€ê²Ÿ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ (Noneì´ë©´ ì˜ˆì¸¡ í´ë˜ìŠ¤ ì‚¬ìš©)
            
        Returns:
            GradCAM íˆíŠ¸ë§µ (H, W)
            
        Raises:
            GradCAMError: GradCAM ìƒì„± ì‹¤íŒ¨ì‹œ
        """
        try:
            if input_tensor.dim() != 4 or input_tensor.size(0) != 1:
                raise GradCAMError("Input tensor must be 4D with batch size 1")
            
            self.model.eval()
            input_tensor.requires_grad_(True)
            
            # Forward pass
            output = self.model(input_tensor)
            
            if target_class is None:
                target_class = output.argmax(dim=1).item()
            
            if target_class >= output.size(1):
                raise GradCAMError(f"Target class {target_class} out of range")
            
            # Backward pass
            self.model.zero_grad()
            score = output[0, target_class]
            score.backward()
            
            # GradCAM ê³„ì‚° ê²€ì¦
            if self.gradients is None or self.activations is None:
                raise GradCAMError("Gradients or activations not captured")
            
            gradients = self.gradients[0]  # (C, H, W)
            activations = self.activations[0]  # (C, H, W)
            
            if gradients.shape != activations.shape:
                raise GradCAMError("Gradients and activations shape mismatch")
            
            # ê°€ì¤‘ì¹˜ ê³„ì‚° (Global Average Pooling)
            weights = torch.mean(gradients, dim=(1, 2))  # (C,)
            
            # Weighted sum
            gradcam = torch.sum(
                weights.unsqueeze(1).unsqueeze(2) * activations, 
                dim=0
            )  # (H, W)
            
            # ReLU ì ìš©
            gradcam = F.relu(gradcam)
            
            # ì •ê·œí™”
            if gradcam.max() > 0:
                gradcam = gradcam / gradcam.max()
            
            # ì…ë ¥ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            target_size = (input_tensor.shape[2], input_tensor.shape[3])
            gradcam = F.interpolate(
                gradcam.unsqueeze(0).unsqueeze(0), 
                size=target_size, 
                mode='bilinear',
                align_corners=False
            ).squeeze()
            
            # ìœ íš¨ì„± ê²€ì¦
            gradcam_np = gradcam.detach().cpu().numpy()
            if np.any(np.isnan(gradcam_np)):
                logger.warning("NaN values detected in GradCAM, using default")
                gradcam_np = np.ones(target_size) * 0.5
            
            return gradcam_np
            
        except Exception as e:
            logger.error(f"GradCAM generation failed: {str(e)}")
            # ê¸°ë³¸ íˆíŠ¸ë§µ ë°˜í™˜
            target_size = (input_tensor.shape[2], input_tensor.shape[3])
            return np.ones(target_size) * 0.5
    
    def cleanup(self):
        """Hook ì •ë¦¬"""
        try:
            if hasattr(self, 'forward_hook'):
                self.forward_hook.remove()
            if hasattr(self, 'backward_hook'):
                self.backward_hook.remove()
            logger.info("GradCAM hooks cleaned up")
        except Exception as e:
            logger.warning(f"Failed to cleanup hooks: {str(e)}")
    
    def __del__(self):
        """ì†Œë©¸ì"""
        self.cleanup()


def extract_roi_from_heatmap(
    heatmap: np.ndarray, 
    percentile: float = 80.0,
    min_area_ratio: float = 0.01
) -> Tuple[float, float, float, float]:
    """
    íˆíŠ¸ë§µì—ì„œ ROI ì¶”ì¶œ
    
    Args:
        heatmap: ì…ë ¥ íˆíŠ¸ë§µ (H, W)
        percentile: ROI ì„ê³„ê°’ ë°±ë¶„ìœ„ìˆ˜
        min_area_ratio: ìµœì†Œ ROI ë©´ì  ë¹„ìœ¨
        
    Returns:
        (x1, y1, x2, y2) ì •ê·œí™”ëœ ì¢Œí‘œ (0~1)
    """
    try:
        if heatmap.ndim != 2:
            raise ValueError("Heatmap must be 2D")
        
        h, w = heatmap.shape
        min_area = int(h * w * min_area_ratio)
        
        # ì„ê³„ê°’ ê³„ì‚°
        threshold = np.percentile(heatmap, percentile)
        
        # ì´ì§„í™”
        binary_mask = heatmap >= threshold
        coords = np.where(binary_mask)
        
        # ìœ íš¨í•œ ì˜ì—­ì´ ì—†ê±°ë‚˜ ë„ˆë¬´ ì‘ì€ ê²½ìš°
        if len(coords[0]) == 0 or len(coords[0]) < min_area:
            logger.warning(f"Insufficient ROI area, using default center region")
            return 0.25, 0.25, 0.75, 0.75
        
        # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
        y1, y2 = coords[0].min(), coords[0].max()
        x1, x2 = coords[1].min(), coords[1].max()
        
        # ì •ê·œí™” ë° ê²½ê³„ í™•ì¸
        x1_norm = max(0.0, min(1.0, x1 / w))
        y1_norm = max(0.0, min(1.0, y1 / h))
        x2_norm = max(0.0, min(1.0, x2 / w))
        y2_norm = max(0.0, min(1.0, y2 / h))
        
        # ìœ íš¨ì„± ê²€ì¦
        if x2_norm <= x1_norm or y2_norm <= y1_norm:
            logger.warning("Invalid ROI coordinates, using default")
            return 0.25, 0.25, 0.75, 0.75
        
        # ìµœì†Œ í¬ê¸° ë³´ì¥
        width = x2_norm - x1_norm
        height = y2_norm - y1_norm
        min_size = 0.1  # ìµœì†Œ 10%
        
        if width < min_size:
            center_x = (x1_norm + x2_norm) / 2
            x1_norm = max(0.0, center_x - min_size/2)
            x2_norm = min(1.0, center_x + min_size/2)
        
        if height < min_size:
            center_y = (y1_norm + y2_norm) / 2
            y1_norm = max(0.0, center_y - min_size/2)
            y2_norm = min(1.0, center_y + min_size/2)
        
        return x1_norm, y1_norm, x2_norm, y2_norm
        
    except Exception as e:
        logger.error(f"ROI extraction failed: {str(e)}")
        return 0.25, 0.25, 0.75, 0.75


def visualize_gradcam_overlay(
    image: np.ndarray, 
    heatmap: np.ndarray, 
    alpha: float = 0.4
) -> np.ndarray:
    """
    ì´ë¯¸ì§€ì™€ GradCAM íˆíŠ¸ë§µ ì˜¤ë²„ë ˆì´
    
    Args:
        image: ì›ë³¸ ì´ë¯¸ì§€ (H, W, 3) ë˜ëŠ” (H, W)
        heatmap: GradCAM íˆíŠ¸ë§µ (H, W)
        alpha: íˆíŠ¸ë§µ íˆ¬ëª…ë„
        
    Returns:
        ì˜¤ë²„ë ˆì´ëœ ì´ë¯¸ì§€ (H, W, 3)
    """
    try:
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        if image.ndim == 3:
            image_norm = image.astype(np.float32) / 255.0
        else:
            image_norm = np.stack([image] * 3, axis=-1).astype(np.float32) / 255.0
        
        # íˆíŠ¸ë§µì„ ì»¬ëŸ¬ë§µìœ¼ë¡œ ë³€í™˜ (ë¹¨ê°„ìƒ‰ ê³„ì—´)
        import matplotlib.cm as cm
        colormap = cm.get_cmap('jet')
        heatmap_colored = colormap(heatmap)[:, :, :3]  # RGBë§Œ ì‚¬ìš©
        
        # ì˜¤ë²„ë ˆì´
        overlay = (1 - alpha) * image_norm + alpha * heatmap_colored
        overlay = np.clip(overlay, 0, 1)
        
        return (overlay * 255).astype(np.uint8)
        
    except Exception as e:
        logger.error(f"Visualization failed: {str(e)}")
        return image if image.ndim == 3 else np.stack([image] * 3, axis=-1)
