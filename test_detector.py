#!/usr/bin/env python3
"""
ğŸ§ª Test Suite for Wafer Defect Detection System
ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œë“¤ì˜ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ë° í†µí•© í…ŒìŠ¤íŠ¸
"""

import unittest
import tempfile
import shutil
import json
from pathlib import Path
from unittest.mock import Mock, patch
import numpy as np
import torch
from PIL import Image

# í…ŒìŠ¤íŠ¸ ëŒ€ìƒ ëª¨ë“ˆë“¤
from wafer_detector import WaferDetector, WaferDetectorError
from gradcam_utils import GradCAMAnalyzer, extract_roi_from_heatmap, GradCAMError
from utils import (
    setup_directories, validate_dataset_structure, 
    create_sample_config, analyze_class_distribution
)


class TestWaferDetector(unittest.TestCase):
    """WaferDetector í´ë˜ìŠ¤ í…ŒìŠ¤íŠ¸"""
    
    def setUp(self):
        """í…ŒìŠ¤íŠ¸ ì¤€ë¹„"""
        self.config = {
            'CLASSIFICATION_SIZE': 224,
            'YOLO_SIZE': 640,
            'PRECISION_THRESHOLD': 0.8,
            'CONFIDENCE_THRESHOLD': 0.7,
            'MAPPING_THRESHOLD': 0.3,
            'OUTPUT_DIR': 'test_output'
        }
        self.detector = WaferDetector(self.config)
    
    def test_initialization(self):
        """ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        self.assertIsNotNone(self.detector)
        self.assertEqual(len(self.detector.classes), 0)
        self.assertEqual(len(self.detector.difficult_classes), 0)
        self.assertIsNotNone(self.detector.transform)
    
    def test_config_validation(self):
        """ì„¤ì • ìœ íš¨ì„± í…ŒìŠ¤íŠ¸"""
        # ì˜ëª»ëœ ì„¤ì •
        invalid_config = {'CLASSIFICATION_SIZE': 'invalid'}
        
        with self.assertRaises(Exception):
            detector = WaferDetector(invalid_config)
            # transform ìƒì„± ì‹œ ì˜¤ë¥˜ ë°œìƒí•  ê²ƒ
    
    def test_get_stats(self):
        """í†µê³„ ì •ë³´ í…ŒìŠ¤íŠ¸"""
        stats = self.detector.get_stats()
        
        self.assertIn('total_classes', stats)
        self.assertIn('difficult_classes', stats)
        self.assertIn('device', stats)
        self.assertIn('models_loaded', stats)
        
        # ì´ˆê¸° ìƒíƒœ í™•ì¸
        self.assertEqual(stats['total_classes'], 0)
        self.assertEqual(stats['difficult_classes'], 0)


class TestGradCAMUtils(unittest.TestCase):
    """GradCAM ìœ í‹¸ë¦¬í‹° í…ŒìŠ¤íŠ¸"""
    
    def test_extract_roi_from_heatmap(self):
        """ROI ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
        # í…ŒìŠ¤íŠ¸ íˆíŠ¸ë§µ ìƒì„±
        heatmap = np.zeros((100, 100))
        heatmap[25:75, 25:75] = 1.0  # ì¤‘ì•™ì— ë†’ì€ ê°’
        
        roi = extract_roi_from_heatmap(heatmap)
        
        # ROI ì¢Œí‘œ í™•ì¸
        self.assertEqual(len(roi), 4)
        x1, y1, x2, y2 = roi
        
        # ì¢Œí‘œ ë²”ìœ„ í™•ì¸
        self.assertTrue(0 <= x1 < x2 <= 1)
        self.assertTrue(0 <= y1 < y2 <= 1)
    
    def test_extract_roi_empty_heatmap(self):
        """ë¹ˆ íˆíŠ¸ë§µ ROI ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
        heatmap = np.zeros((100, 100))
        
        roi = extract_roi_from_heatmap(heatmap)
        
        # ê¸°ë³¸ê°’ ë°˜í™˜ í™•ì¸
        self.assertEqual(roi, (0.25, 0.25, 0.75, 0.75))
    
    def test_extract_roi_invalid_input(self):
        """ì˜ëª»ëœ ì…ë ¥ ROI ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
        # 1D ë°°ì—´
        invalid_heatmap = np.zeros(100)
        
        roi = extract_roi_from_heatmap(invalid_heatmap)
        
        # ê¸°ë³¸ê°’ ë°˜í™˜ í™•ì¸
        self.assertEqual(roi, (0.25, 0.25, 0.75, 0.75))


class TestUtils(unittest.TestCase):
    """ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
    
    def setUp(self):
        """í…ŒìŠ¤íŠ¸ ì¤€ë¹„"""
        self.temp_dir = tempfile.mkdtemp()
        self.temp_path = Path(self.temp_dir)
    
    def tearDown(self):
        """í…ŒìŠ¤íŠ¸ ì •ë¦¬"""
        shutil.rmtree(self.temp_dir)
    
    def test_setup_directories(self):
        """ë””ë ‰í† ë¦¬ ì„¤ì • í…ŒìŠ¤íŠ¸"""
        output_dir = self.temp_path / 'output'
        
        dirs = setup_directories(output_dir)
        
        # ë””ë ‰í† ë¦¬ ìƒì„± í™•ì¸
        self.assertTrue(output_dir.exists())
        self.assertIn('root', dirs)
        self.assertIn('results', dirs)
        self.assertIn('visualizations', dirs)
        
        # ì‹¤ì œ ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸
        for dir_path in dirs.values():
            self.assertTrue(dir_path.exists())
    
    def test_create_sample_config(self):
        """ìƒ˜í”Œ ì„¤ì • ìƒì„± í…ŒìŠ¤íŠ¸"""
        config = create_sample_config()
        
        self.assertIn('high_speed_mode', config)
        self.assertIn('high_accuracy_mode', config)
        self.assertIn('balanced_mode', config)
        
        # ê° ëª¨ë“œë³„ ì„¤ì • í™•ì¸
        for mode in ['high_speed_mode', 'high_accuracy_mode', 'balanced_mode']:
            mode_config = config[mode]
            self.assertIn('PRECISION_THRESHOLD', mode_config)
            self.assertIn('CONFIDENCE_THRESHOLD', mode_config)
    
    def test_validate_dataset_structure_empty(self):
        """ë¹ˆ ë°ì´í„°ì…‹ êµ¬ì¡° ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        result = validate_dataset_structure(self.temp_path)
        
        self.assertFalse(result['valid'])
        self.assertIn('error', result)
    
    def test_validate_dataset_structure_valid(self):
        """ìœ íš¨í•œ ë°ì´í„°ì…‹ êµ¬ì¡° ê²€ì¦ í…ŒìŠ¤íŠ¸"""
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ êµ¬ì¡° ìƒì„±
        class_dirs = ['normal', 'defect']
        
        for class_name in class_dirs:
            class_dir = self.temp_path / class_name
            class_dir.mkdir()
            
            # ë”ë¯¸ ì´ë¯¸ì§€ íŒŒì¼ ìƒì„±
            for i in range(3):
                img_path = class_dir / f'image_{i}.jpg'
                
                # ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
                img = Image.new('RGB', (100, 100), color='white')
                img.save(img_path)
        
        result = validate_dataset_structure(self.temp_path)
        
        self.assertTrue(result['valid'])
        self.assertEqual(result['total_classes'], 2)
        self.assertEqual(len(result['classes']), 2)


class TestIntegration(unittest.TestCase):
    """í†µí•© í…ŒìŠ¤íŠ¸"""
    
    def setUp(self):
        """í…ŒìŠ¤íŠ¸ ì¤€ë¹„"""
        self.temp_dir = tempfile.mkdtemp()
        self.temp_path = Path(self.temp_dir)
        
        self.config = {
            'CLASSIFICATION_SIZE': 224,
            'YOLO_SIZE': 640,
            'PRECISION_THRESHOLD': 0.8,
            'CONFIDENCE_THRESHOLD': 0.7,
            'MAPPING_THRESHOLD': 0.3,
            'OUTPUT_DIR': str(self.temp_path / 'output')
        }
    
    def tearDown(self):
        """í…ŒìŠ¤íŠ¸ ì •ë¦¬"""
        shutil.rmtree(self.temp_dir)
    
    def test_config_save_load(self):
        """ì„¤ì • ì €ì¥/ë¡œë“œ í…ŒìŠ¤íŠ¸"""
        config_path = self.temp_path / 'test_config.json'
        
        # ì„¤ì • ì €ì¥
        with open(config_path, 'w') as f:
            json.dump(self.config, f, indent=2)
        
        # ì„¤ì • ë¡œë“œ
        with open(config_path, 'r') as f:
            loaded_config = json.load(f)
        
        self.assertEqual(self.config, loaded_config)
    
    @patch('wafer_detector.timm.create_model')
    @patch('wafer_detector.torch.load')
    @patch('wafer_detector.YOLO')
    def test_detector_initialization_with_mocks(self, mock_yolo, mock_torch_load, mock_timm):
        """Mockì„ ì‚¬ìš©í•œ ê²€ì¶œê¸° ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸"""
        # Mock ì„¤ì •
        mock_model = Mock()
        mock_model.head.fc.in_features = 1024
        mock_timm.return_value = mock_model
        
        mock_state_dict = {
            'head.fc.weight': torch.randn(5, 1024),  # 5 í´ë˜ìŠ¤
            'head.fc.bias': torch.randn(5)
        }
        mock_torch_load.return_value = mock_state_dict
        
        mock_yolo_instance = Mock()
        mock_yolo.return_value = mock_yolo_instance
        
        # í…ŒìŠ¤íŠ¸
        detector = WaferDetector(self.config)
        
        # ê°€ì§œ ëª¨ë¸ ê²½ë¡œë¡œ ë¡œë“œ ì‹œë„
        detector.load_models('fake_model.pth', 'fake_yolo.pt')
        
        # Mock í˜¸ì¶œ í™•ì¸
        mock_timm.assert_called_once()
        mock_torch_load.assert_called_once()
        mock_yolo.assert_called_once()


class TestErrorHandling(unittest.TestCase):
    """ì˜¤ë¥˜ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸"""
    
    def test_wafer_detector_error(self):
        """WaferDetectorError í…ŒìŠ¤íŠ¸"""
        with self.assertRaises(WaferDetectorError):
            raise WaferDetectorError("Test error")
    
    def test_gradcam_error(self):
        """GradCAMError í…ŒìŠ¤íŠ¸"""
        with self.assertRaises(GradCAMError):
            raise GradCAMError("Test error")
    
    def test_detector_without_models(self):
        """ëª¨ë¸ ì—†ì´ ê²€ì¶œê¸° ì‚¬ìš© í…ŒìŠ¤íŠ¸"""
        config = {
            'CLASSIFICATION_SIZE': 224,
            'YOLO_SIZE': 640,
            'PRECISION_THRESHOLD': 0.8,
            'CONFIDENCE_THRESHOLD': 0.7,
            'MAPPING_THRESHOLD': 0.3
        }
        detector = WaferDetector(config)
        
        # í´ë˜ìŠ¤ ë¡œë“œ ì—†ì´ ì˜ˆì¸¡ ì‹œë„
        with self.assertRaises(WaferDetectorError):
            detector.predict_image('fake_image.jpg')


def create_test_dataset(root_path: Path, num_classes: int = 3, images_per_class: int = 5):
    """
    í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°ì…‹ ìƒì„±
    
    Args:
        root_path: ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ
        num_classes: í´ë˜ìŠ¤ ìˆ˜
        images_per_class: í´ë˜ìŠ¤ë‹¹ ì´ë¯¸ì§€ ìˆ˜
    """
    class_names = [f'class_{i}' for i in range(num_classes)]
    
    for class_name in class_names:
        class_dir = root_path / class_name
        class_dir.mkdir(parents=True, exist_ok=True)
        
        for i in range(images_per_class):
            # ëœë¤ ì»¬ëŸ¬ ì´ë¯¸ì§€ ìƒì„±
            img_array = np.random.randint(0, 255, (100, 100, 3), dtype=np.uint8)
            img = Image.fromarray(img_array)
            
            img_path = class_dir / f'image_{i:03d}.jpg'
            img.save(img_path)


def run_performance_test():
    """ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    import time
    
    # ë”ë¯¸ ë°ì´í„°ë¡œ ì„±ëŠ¥ ì¸¡ì •
    config = {
        'CLASSIFICATION_SIZE': 224,
        'YOLO_SIZE': 640,
        'PRECISION_THRESHOLD': 0.8,
        'CONFIDENCE_THRESHOLD': 0.7,
        'MAPPING_THRESHOLD': 0.3
    }
    
    detector = WaferDetector(config)
    
    # Transform ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    img = Image.new('RGB', (1024, 1024), color='white')
    
    start_time = time.time()
    for _ in range(100):
        tensor = detector.transform(img)
    transform_time = time.time() - start_time
    
    print(f"Transform 100 images: {transform_time:.3f}s")
    print(f"Average per image: {transform_time/100*1000:.2f}ms")


if __name__ == '__main__':
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    unittest.main(verbosity=2)
