#!/usr/bin/env python3
"""
ğŸ› ï¸ Utility Functions for Wafer Defect Detection
ì´ë¯¸ì§€ ì²˜ë¦¬, ì‹œê°í™”, ì„±ëŠ¥ í‰ê°€ ë“± ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ëª¨ìŒ
"""

import json
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any, Union

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image, ImageDraw
import torch
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import precision_recall_fscore_support

logger = logging.getLogger(__name__)


def setup_directories(output_dir: Union[str, Path]) -> Dict[str, Path]:
    """
    ì¶œë ¥ ë””ë ‰í† ë¦¬ êµ¬ì¡° ì„¤ì •
    
    Args:
        output_dir: ê¸°ë³¸ ì¶œë ¥ ë””ë ‰í† ë¦¬
        
    Returns:
        ìƒì„±ëœ ë””ë ‰í† ë¦¬ ê²½ë¡œë“¤
    """
    output_dir = Path(output_dir)
    
    dirs = {
        'root': output_dir,
        'models': output_dir / 'models',
        'results': output_dir / 'results',
        'visualizations': output_dir / 'visualizations',
        'logs': output_dir / 'logs',
        'heatmaps': output_dir / 'visualizations' / 'heatmaps',
        'roi_images': output_dir / 'visualizations' / 'roi_images',
        'confusion_matrices': output_dir / 'visualizations' / 'confusion_matrices'
    }
    
    for dir_path in dirs.values():
        dir_path.mkdir(parents=True, exist_ok=True)
    
    logger.info(f"Directory structure created at {output_dir}")
    return dirs


def save_prediction_visualization(
    image_path: Union[str, Path],
    result: Dict[str, Any],
    output_path: Union[str, Path],
    show_roi: bool = True
) -> None:
    """
    ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” ì €ì¥
    
    Args:
        image_path: ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
        result: ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        output_path: ì €ì¥ ê²½ë¡œ
        show_roi: ROI ì˜ì—­ í‘œì‹œ ì—¬ë¶€
    """
    try:
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(image_path).convert('RGB')
        fig, ax = plt.subplots(1, 1, figsize=(10, 8))
        
        # ì´ë¯¸ì§€ í‘œì‹œ
        ax.imshow(image)
        
        # ì˜ˆì¸¡ ì •ë³´ í…ìŠ¤íŠ¸
        title = f"Predicted: {result['predicted_class']} ({result['confidence']:.3f})"
        if result['method'] == 'roi_enhanced':
            title += f"\nMethod: ROI Enhanced ({result.get('detected_object', 'N/A')})"
        else:
            title += "\nMethod: Classification Only"
        
        ax.set_title(title, fontsize=14, fontweight='bold')
        
        # ROI ì˜ì—­ í‘œì‹œ
        if show_roi and 'roi_coordinates' in result:
            roi = result['roi_coordinates']
            w, h = image.size
            
            x1 = roi['x1'] * w
            y1 = roi['y1'] * h
            x2 = roi['x2'] * w
            y2 = roi['y2'] * h
            
            # ROI ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            from matplotlib.patches import Rectangle
            rect = Rectangle(
                (x1, y1), x2 - x1, y2 - y1,
                linewidth=3, edgecolor='red', facecolor='none'
            )
            ax.add_patch(rect)
            ax.text(x1, y1 - 10, 'ROI', color='red', fontweight='bold', fontsize=12)
        
        ax.axis('off')
        plt.tight_layout()
        
        # ì €ì¥
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        logger.info(f"Visualization saved to {output_path}")
        
    except Exception as e:
        logger.error(f"Failed to save visualization: {e}")


def create_confusion_matrix_plot(
    y_true: List[int],
    y_pred: List[int],
    class_names: List[str],
    output_path: Union[str, Path],
    normalize: bool = True
) -> None:
    """
    í˜¼ë™ í–‰ë ¬ í”Œë¡¯ ìƒì„± ë° ì €ì¥
    
    Args:
        y_true: ì‹¤ì œ ë ˆì´ë¸”
        y_pred: ì˜ˆì¸¡ ë ˆì´ë¸”
        class_names: í´ë˜ìŠ¤ ì´ë¦„ ëª©ë¡
        output_path: ì €ì¥ ê²½ë¡œ
        normalize: ì •ê·œí™” ì—¬ë¶€
    """
    try:
        # í˜¼ë™ í–‰ë ¬ ê³„ì‚°
        cm = confusion_matrix(y_true, y_pred)
        
        if normalize:
            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
            fmt = '.2f'
            title = 'Normalized Confusion Matrix'
        else:
            fmt = 'd'
            title = 'Confusion Matrix'
        
        # í”Œë¡¯ ìƒì„±
        plt.figure(figsize=(10, 8))
        sns.heatmap(
            cm, 
            annot=True, 
            fmt=fmt, 
            cmap='Blues',
            xticklabels=class_names,
            yticklabels=class_names
        )
        
        plt.title(title, fontsize=16, fontweight='bold')
        plt.xlabel('Predicted Label', fontsize=14)
        plt.ylabel('True Label', fontsize=14)
        plt.xticks(rotation=45)
        plt.yticks(rotation=0)
        plt.tight_layout()
        
        # ì €ì¥
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        logger.info(f"Confusion matrix saved to {output_path}")
        
    except Exception as e:
        logger.error(f"Failed to create confusion matrix: {e}")


def generate_performance_report(
    y_true: List[int],
    y_pred: List[int],
    class_names: List[str],
    output_path: Union[str, Path]
) -> Dict[str, Any]:
    """
    ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„± ë° ì €ì¥
    
    Args:
        y_true: ì‹¤ì œ ë ˆì´ë¸”
        y_pred: ì˜ˆì¸¡ ë ˆì´ë¸”
        class_names: í´ë˜ìŠ¤ ì´ë¦„ ëª©ë¡
        output_path: ì €ì¥ ê²½ë¡œ
        
    Returns:
        ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬
    """
    try:
        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê³„ì‚°
        precision, recall, f1, support = precision_recall_fscore_support(
            y_true, y_pred, average=None, zero_division=0
        )
        
        # ì „ì²´ í‰ê· 
        precision_avg, recall_avg, f1_avg, _ = precision_recall_fscore_support(
            y_true, y_pred, average='weighted', zero_division=0
        )
        
        # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥
        class_metrics = {}
        for i, class_name in enumerate(class_names):
            class_metrics[class_name] = {
                'precision': float(precision[i]),
                'recall': float(recall[i]),
                'f1_score': float(f1[i]),
                'support': int(support[i])
            }
        
        # ì „ì²´ ì„±ëŠ¥
        overall_metrics = {
            'precision_weighted': float(precision_avg),
            'recall_weighted': float(recall_avg),
            'f1_weighted': float(f1_avg),
            'accuracy': float(np.mean(np.array(y_true) == np.array(y_pred)))
        }
        
        # ì„±ëŠ¥ ë¦¬í¬íŠ¸
        performance_report = {
            'overall_metrics': overall_metrics,
            'class_metrics': class_metrics,
            'classification_report': classification_report(
                y_true, y_pred, target_names=class_names, output_dict=True
            )
        }
        
        # JSON ì €ì¥
        with open(output_path, 'w') as f:
            json.dump(performance_report, f, indent=2)
        
        logger.info(f"Performance report saved to {output_path}")
        return performance_report
        
    except Exception as e:
        logger.error(f"Failed to generate performance report: {e}")
        return {}


def visualize_roi_patterns(
    roi_patterns: Dict[str, Dict[str, float]],
    output_dir: Union[str, Path],
    image_size: Tuple[int, int] = (384, 384)
) -> None:
    """
    ROI íŒ¨í„´ ì‹œê°í™”
    
    Args:
        roi_patterns: ROI íŒ¨í„´ ë”•ì…”ë„ˆë¦¬
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        image_size: ê¸°ì¤€ ì´ë¯¸ì§€ í¬ê¸°
    """
    try:
        output_dir = Path(output_dir)
        
        # ì „ì²´ ROI íŒ¨í„´ ë¹„êµ
        fig, axes = plt.subplots(
            2, (len(roi_patterns) + 1) // 2, 
            figsize=(15, 10)
        )
        axes = axes.flatten() if len(roi_patterns) > 1 else [axes]
        
        for i, (class_name, roi) in enumerate(roi_patterns.items()):
            if i >= len(axes):
                break
                
            ax = axes[i]
            
            # ë°°ê²½ ì´ë¯¸ì§€ (íšŒìƒ‰)
            background = np.ones((*image_size, 3)) * 0.8
            ax.imshow(background)
            
            # ROI ì˜ì—­ í‘œì‹œ
            w, h = image_size
            x1 = roi['x1'] * w
            y1 = roi['y1'] * h
            x2 = roi['x2'] * w
            y2 = roi['y2'] * h
            
            from matplotlib.patches import Rectangle
            rect = Rectangle(
                (x1, y1), x2 - x1, y2 - y1,
                linewidth=3, edgecolor='red', facecolor='red', alpha=0.3
            )
            ax.add_patch(rect)
            
            ax.set_title(f"{class_name}\nROI Pattern", fontweight='bold')
            ax.axis('off')
        
        # ë¹ˆ subplot ìˆ¨ê¸°ê¸°
        for i in range(len(roi_patterns), len(axes)):
            axes[i].axis('off')
        
        plt.suptitle('ROI Patterns for Difficult Classes', fontsize=16, fontweight='bold')
        plt.tight_layout()
        
        # ì €ì¥
        plt.savefig(output_dir / 'roi_patterns_overview.png', dpi=150, bbox_inches='tight')
        plt.close()
        
        logger.info(f"ROI patterns visualization saved to {output_dir}")
        
    except Exception as e:
        logger.error(f"Failed to visualize ROI patterns: {e}")


def analyze_class_distribution(
    dataset_root: Union[str, Path],
    output_path: Union[str, Path]
) -> Dict[str, int]:
    """
    ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„
    
    Args:
        dataset_root: ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ
        output_path: ê²°ê³¼ ì €ì¥ ê²½ë¡œ
        
    Returns:
        í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜
    """
    try:
        dataset_root = Path(dataset_root)
        class_counts = {}
        
        # í´ë˜ìŠ¤ë³„ íŒŒì¼ ìˆ˜ ê³„ì‚°
        for class_dir in dataset_root.iterdir():
            if class_dir.is_dir():
                image_files = (
                    list(class_dir.glob("*.jpg")) + 
                    list(class_dir.glob("*.png")) + 
                    list(class_dir.glob("*.jpeg"))
                )
                class_counts[class_dir.name] = len(image_files)
        
        # ì‹œê°í™”
        plt.figure(figsize=(12, 6))
        classes = list(class_counts.keys())
        counts = list(class_counts.values())
        
        bars = plt.bar(classes, counts, color='skyblue', alpha=0.7)
        plt.title('Class Distribution in Dataset', fontsize=16, fontweight='bold')
        plt.xlabel('Class', fontsize=14)
        plt.ylabel('Number of Samples', fontsize=14)
        plt.xticks(rotation=45)
        
        # ê°’ í‘œì‹œ
        for bar, count in zip(bars, counts):
            plt.text(
                bar.get_x() + bar.get_width()/2, 
                bar.get_height() + max(counts) * 0.01,
                str(count), 
                ha='center', 
                va='bottom',
                fontweight='bold'
            )
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close()
        
        logger.info(f"Class distribution analysis saved to {output_path}")
        return class_counts
        
    except Exception as e:
        logger.error(f"Failed to analyze class distribution: {e}")
        return {}


def validate_dataset_structure(dataset_root: Union[str, Path]) -> Dict[str, Any]:
    """
    ë°ì´í„°ì…‹ êµ¬ì¡° ìœ íš¨ì„± ê²€ì¦
    
    Args:
        dataset_root: ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ
        
    Returns:
        ê²€ì¦ ê²°ê³¼
    """
    try:
        dataset_root = Path(dataset_root)
        
        if not dataset_root.exists():
            return {'valid': False, 'error': 'Dataset root does not exist'}
        
        # í´ë˜ìŠ¤ ë””ë ‰í† ë¦¬ í™•ì¸
        class_dirs = [d for d in dataset_root.iterdir() if d.is_dir()]
        
        if not class_dirs:
            return {'valid': False, 'error': 'No class directories found'}
        
        validation_result = {
            'valid': True,
            'total_classes': len(class_dirs),
            'classes': [],
            'total_images': 0,
            'issues': []
        }
        
        # ê° í´ë˜ìŠ¤ ê²€ì¦
        for class_dir in class_dirs:
            image_files = (
                list(class_dir.glob("*.jpg")) + 
                list(class_dir.glob("*.png")) + 
                list(class_dir.glob("*.jpeg"))
            )
            
            class_info = {
                'name': class_dir.name,
                'image_count': len(image_files),
                'valid_images': 0,
                'invalid_images': []
            }
            
            # ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦
            for img_file in image_files[:10]:  # ì²˜ìŒ 10ê°œë§Œ ìƒ˜í”Œ ê²€ì¦
                try:
                    with Image.open(img_file) as img:
                        img.verify()
                    class_info['valid_images'] += 1
                except Exception as e:
                    class_info['invalid_images'].append(str(img_file))
            
            validation_result['classes'].append(class_info)
            validation_result['total_images'] += class_info['image_count']
            
            # ì´ìŠˆ ì²´í¬
            if class_info['image_count'] == 0:
                validation_result['issues'].append(f"No images in {class_dir.name}")
            elif class_info['image_count'] < 10:
                validation_result['issues'].append(f"Very few images in {class_dir.name}: {class_info['image_count']}")
        
        return validation_result
        
    except Exception as e:
        return {'valid': False, 'error': str(e)}


def create_sample_config() -> Dict[str, Any]:
    """
    ìƒ˜í”Œ ì„¤ì • ìƒì„±
    
    Returns:
        ìƒ˜í”Œ ì„¤ì • ë”•ì…”ë„ˆë¦¬
    """
    return {
        "description": "Sample configuration for different use cases",
        
        "high_speed_mode": {
            "F1_THRESHOLD": 0.9,
            "CONFIDENCE_THRESHOLD": 0.8,
            "MAPPING_THRESHOLD": 0.4,
            "max_roi_samples": 5,
            "max_mapping_samples": 15
        },
        
        "high_accuracy_mode": {
            "F1_THRESHOLD": 0.7,
            "CONFIDENCE_THRESHOLD": 0.6,
            "MAPPING_THRESHOLD": 0.2,
            "max_roi_samples": 20,
            "max_mapping_samples": 50
        },
        
        "balanced_mode": {
            "F1_THRESHOLD": 0.8,
            "CONFIDENCE_THRESHOLD": 0.7,
            "MAPPING_THRESHOLD": 0.3,
            "max_roi_samples": 10,
            "max_mapping_samples": 30
        }
    }


def log_system_info() -> None:
    """ì‹œìŠ¤í…œ ì •ë³´ ë¡œê¹…"""
    try:
        import torch
        import platform
        
        logger.info("=== System Information ===")
        logger.info(f"Platform: {platform.platform()}")
        logger.info(f"Python: {platform.python_version()}")
        logger.info(f"PyTorch: {torch.__version__}")
        logger.info(f"CUDA Available: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            logger.info(f"CUDA Version: {torch.version.cuda}")
            logger.info(f"GPU Count: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                gpu_name = torch.cuda.get_device_name(i)
                logger.info(f"GPU {i}: {gpu_name}")
        
        logger.info("=" * 30)
        
    except Exception as e:
        logger.warning(f"Failed to log system info: {e}")
