#!/usr/bin/env python3
"""
ğŸ¯ WaferDetector - ì›¨ì´í¼ ê²°í•¨ ê²€ì¶œ ì‹œìŠ¤í…œ
ì§€ëŠ¥í˜• 2ë‹¨ê³„ ê²€ì¶œ: ê¸°ë³¸ ë¶„ë¥˜ + ROI ê¸°ë°˜ ì •ë°€ ê²€ì¦
"""

import os
import json
import logging
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any, Union

import torch
import torch.nn as nn
import numpy as np
from PIL import Image
import timm
from ultralytics import YOLO
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from sklearn.metrics import precision_recall_fscore_support, precision_score, recall_score, f1_score, confusion_matrix

from gradcam_utils import GradCAMAnalyzer, extract_roi_from_heatmap

logger = logging.getLogger(__name__)


class WaferDetectorError(Exception):
    """ì›¨ì´í¼ ê²€ì¶œê¸° ê´€ë ¨ ì˜ˆì™¸"""
    pass


class WaferDetector:
    """
    ì§€ëŠ¥í˜• ì›¨ì´í¼ ê²°í•¨ ê²€ì¶œê¸°
    
    2ë‹¨ê³„ ê²€ì¶œ ì‹œìŠ¤í…œ:
    1. ê¸°ë³¸ ë¶„ë¥˜ (ëª¨ë“  ì´ë¯¸ì§€)
    2. ROI ê¸°ë°˜ ì •ë°€ ê²€ì¦ (ì–´ë ¤ìš´ í´ë˜ìŠ¤ + ë‚®ì€ ì‹ ë¢°ë„)
    """
    
    def __init__(self, config: Dict[str, Any]):
        """
        ì´ˆê¸°í™”
        
        Args:
            config: ì„¤ì • ë”•ì…”ë„ˆë¦¬
        """
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.classification_model = None
        self.yolo_model = None
        self.gradcam_analyzer = None
        
        # í´ë˜ìŠ¤ ë° íŒ¨í„´ ì •ë³´
        self.classes: List[str] = []
        self.difficult_classes: List[str] = []
        self.class_object_mapping: Dict[str, str] = {}
        self.roi_patterns: Dict[str, Dict[str, float]] = {}
        self.precision_scores: Optional[np.ndarray] = None
        self.f1_scores: Optional[np.ndarray] = None
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        self.transform = transforms.Compose([
            transforms.Resize((config['CLASSIFICATION_SIZE'], config['CLASSIFICATION_SIZE'])),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        logger.info(f"WaferDetector initialized - Device: {self.device}")
    
    def load_models(self, model_path: Union[str, Path], yolo_path: Union[str, Path]) -> None:
        """
        ëª¨ë¸ ë¡œë“œ
        
        Args:
            model_path: ë¶„ë¥˜ ëª¨ë¸ ê²½ë¡œ
            yolo_path: YOLO ëª¨ë¸ ê²½ë¡œ
            
        Raises:
            WaferDetectorError: ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ì‹œ
        """
        try:
            # 1. ê°€ì¤‘ì¹˜ ë¡œë“œ ë° prefix ì œê±°
            logger.info("Loading model weights...")
            state_dict = torch.load(model_path, map_location="cpu")
            
            # model prefixê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì œê±°
            if any(k.startswith('model.') for k in state_dict.keys()):
                cleaned_state_dict = {k.replace('model.', ''): v for k, v in state_dict.items()}
                logger.info("Removed 'model.' prefix from state dict")
            else:
                cleaned_state_dict = state_dict
                logger.info("No 'model.' prefix found in state dict")
            
            # 2. í´ë˜ìŠ¤ ìˆ˜ ê²°ì • (pth íŒŒì¼ ê¸°ì¤€)
            if 'head.fc.weight' not in cleaned_state_dict:
                raise WaferDetectorError("Invalid model weights: missing head.fc.weight")
            num_classes = cleaned_state_dict['head.fc.weight'].shape[0]
            logger.info(f"Detected {num_classes} classes from model weights")

            # 3. ConvNeXtV2 ëª¨ë¸ ìƒì„± (pth íŒŒì¼ì˜ í´ë˜ìŠ¤ ìˆ˜ë¡œ)
            logger.info("Creating ConvNeXtV2 model...")
            self.classification_model = timm.create_model(
                'convnextv2_base.fcmae_ft_in22k_in1k',
                pretrained=False,  # ê°€ì¤‘ì¹˜ë¥¼ ì§ì ‘ ë¡œë“œí•  ê²ƒì´ë¯€ë¡œ False
                num_classes=num_classes
            )
            
            # 4. ê°€ì¤‘ì¹˜ ë¡œë“œ
            self.classification_model.load_state_dict(cleaned_state_dict, strict=True)
            logger.info("Model weights loaded successfully")
            
            # 5. ë¶„ë¥˜ê¸°ë¥¼ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ìˆ˜ë¡œ ë³€ê²½ (ë‚˜ì¤‘ì— load_classesì—ì„œ ì„¤ì •ë¨)
            # ì´ ë¶€ë¶„ì€ load_classesì—ì„œ ì²˜ë¦¬ë¨
            
            # YOLO ëª¨ë¸ ë¡œë“œ
            if not Path(yolo_path).exists():
                raise WaferDetectorError(f"YOLO model not found: {yolo_path}")
            
            self.yolo_model = YOLO(yolo_path)
            logger.info("YOLO model loaded successfully")
            
            # GradCAM ì´ˆê¸°í™”
            self.gradcam_analyzer = GradCAMAnalyzer(
                self.classification_model,
                target_layer_name=self.config['advanced']['target_layer_name']
            )
            
            # ëª¨ë¸ì„ ë””ë°”ì´ìŠ¤ë¡œ ì´ë™
            self.classification_model.to(self.device)
            self.classification_model.eval()
            
            logger.info(f"Models loaded successfully - Classes: {num_classes}")
            
        except Exception as e:
            raise WaferDetectorError(f"Failed to load models: {str(e)}")
    
    def load_classes(self, dataset_root: Union[str, Path]) -> None:
        """
        ë°ì´í„°ì…‹ì—ì„œ í´ë˜ìŠ¤ ë¡œë“œ
        
        Args:
            dataset_root: ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ
            
        Raises:
            WaferDetectorError: í´ë˜ìŠ¤ ë¡œë“œ ì‹¤íŒ¨ì‹œ
        """
        try:
            dataset_root = Path(dataset_root)
            if not dataset_root.exists():
                raise WaferDetectorError(f"Dataset root not found: {dataset_root}")
            
            # ImageFolderë¡œ í´ë˜ìŠ¤ ë¡œë“œ
            dataset = datasets.ImageFolder(str(dataset_root), transform=self.transform)
            self.classes = dataset.classes
            
            # ë¶„ë¥˜ê¸°ë¥¼ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ìˆ˜ë¡œ ë³€ê²½
            if self.classification_model is not None:
                num_features = self.classification_model.head.fc.in_features
                
                # ìƒˆë¡œìš´ ë¶„ë¥˜ê¸° ìƒì„± (ì™„ì „íˆ ìƒˆë¡œ ì´ˆê¸°í™”)
                new_fc = nn.Linear(num_features, len(self.classes))
                nn.init.xavier_uniform_(new_fc.weight)
                nn.init.zeros_(new_fc.bias)
                
                self.classification_model.head.fc = new_fc
                logger.info(f"Classifier reset to {len(self.classes)} classes (random initialization)")
            
            logger.info(f"Classes loaded: {self.classes}")
            
        except Exception as e:
            raise WaferDetectorError(f"Failed to load classes: {str(e)}")
    
    def analyze_performance(self, dataset_root: Union[str, Path]) -> np.ndarray:
        """
        ì„±ëŠ¥ ë¶„ì„ ë° ì–´ë ¤ìš´ í´ë˜ìŠ¤ ì‹ë³„
        
        Args:
            dataset_root: ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ
            
        Returns:
            Precision ìŠ¤ì½”ì–´ ë°°ì—´
            
        Raises:
            WaferDetectorError: ì„±ëŠ¥ ë¶„ì„ ì‹¤íŒ¨ì‹œ
        """
        try:
            if self.classification_model is None:
                raise WaferDetectorError("Classification model not loaded")
                
            dataset_root = Path(dataset_root)
            dataset = datasets.ImageFolder(str(dataset_root), transform=self.transform)
            dataloader = DataLoader(
                dataset, 
                batch_size=32, 
                shuffle=False, 
                num_workers=min(2, torch.get_num_threads())
            )
            self.classes = dataset.classes
            
            logger.info(f"Analyzing performance on {len(dataset)} samples...")
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            all_preds, all_labels = [], []
            self.classification_model.eval()
            
            with torch.no_grad():
                for batch_idx, (images, labels) in enumerate(dataloader):
                    images = images.to(self.device)
                    outputs = self.classification_model(images)
                    preds = outputs.argmax(dim=1).cpu().numpy()
                    all_preds.extend(preds)
                    all_labels.extend(labels.numpy())
                    
                    if batch_idx % 10 == 0:
                        logger.info(f"Processed {batch_idx * 32}/{len(dataset)} samples")
            
            # í´ë˜ìŠ¤ ìˆ˜ ë¶ˆì¼ì¹˜ í™•ì¸
            model_classes = self.classification_model.head.fc.out_features
            dataset_classes = len(self.classes)
            
            if model_classes != dataset_classes:
                logger.warning(f"Model has {model_classes} classes but dataset has {dataset_classes} classes")
                logger.warning("Performance analysis may not be accurate - using model's class indices")
                
                # ëª¨ë¸ì˜ í´ë˜ìŠ¤ ìˆ˜ì— ë§ê²Œ ì˜ˆì¸¡ê°’ê³¼ ë ˆì´ë¸” ì¡°ì •
                adjusted_preds = [pred % dataset_classes for pred in all_preds]
                adjusted_labels = [label % dataset_classes for label in all_labels]
                all_preds = adjusted_preds
                all_labels = adjusted_labels
            
            # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
            precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)
            recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)
            f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)
            
            # í´ë˜ìŠ¤ë³„ ìƒì„¸ ë©”íŠ¸ë¦­
            class_precision = precision_score(all_labels, all_preds, average=None, zero_division=0)
            class_recall = recall_score(all_labels, all_preds, average=None, zero_division=0)
            class_f1 = f1_score(all_labels, all_preds, average=None, zero_division=0)
            
            # Confusion Matrix ìƒì„±
            cm = confusion_matrix(all_labels, all_preds)
            
            # ê²°ê³¼ ì¶œë ¥
            logger.info("=" * 60)
            logger.info("PERFORMANCE ANALYSIS RESULTS")
            logger.info("=" * 60)
            logger.info(f"Overall Metrics:")
            logger.info(f"  Precision: {precision:.4f}")
            logger.info(f"  Recall: {recall:.4f}")
            logger.info(f"  F1-Score: {f1:.4f}")
            logger.info("")
            logger.info("Class-wise Metrics:")
            for i, class_name in enumerate(self.classes):
                logger.info(f"  {class_name}:")
                logger.info(f"    Precision: {class_precision[i]:.4f}")
                logger.info(f"    Recall: {class_recall[i]:.4f}")
                logger.info(f"    F1-Score: {class_f1[i]:.4f}")
            logger.info("=" * 60)
            
            # ì–´ë ¤ìš´ í´ë˜ìŠ¤ ì‹ë³„ (Precision ê¸°ì¤€)
            self.difficult_classes = [
                self.classes[i] for i, prec in enumerate(class_precision) 
                if prec < self.config['PRECISION_THRESHOLD']
            ]
            logger.info(f"Identified {len(self.difficult_classes)} difficult classes: {self.difficult_classes}")
            
            # ë©”íŠ¸ë¦­ì„ TXT íŒŒì¼ë¡œ ì €ì¥
            self.save_metrics_to_txt(cm, class_precision, class_recall, class_f1, precision, recall, f1)
            
            # ê²°ê³¼ ì €ì¥
            performance_results = {
                'overall': {
                    'precision': precision,
                    'recall': recall,
                    'f1_score': f1
                },
                'class_wise': {
                    class_name: {
                        'precision': float(class_precision[i]),
                        'recall': float(class_recall[i]),
                        'f1_score': float(class_f1[i])
                    } for i, class_name in enumerate(self.classes)
                },
                'confusion_matrix': cm.tolist(),
                'class_names': self.classes,
                'difficult_classes': self.difficult_classes
            }
            
            # Confusion Matrix ì‹œê°í™” ë° ì €ì¥
            self.save_confusion_matrix(cm, self.classes)
            
            return performance_results
            
        except Exception as e:
            raise WaferDetectorError(f"Performance analysis failed: {str(e)}")
    
    def analyze_prediction_performance(self, predictions, dataset_path):
        """ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„±ëŠ¥ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        try:
            logger.info("Analyzing prediction performance...")
            
            # ì‹¤ì œ í´ë˜ìŠ¤ì™€ ì˜ˆì¸¡ í´ë˜ìŠ¤ ìˆ˜ì§‘
            all_labels = []
            all_preds = []
            
            for pred in predictions:
                image_path = pred['image_path']
                predicted_class = pred['predicted_class']
                
                # ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ ì‹¤ì œ í´ë˜ìŠ¤ ì¶”ì¶œ
                actual_class = self._extract_class_from_path(image_path, dataset_path)
                
                if actual_class in self.classes:
                    actual_idx = self.classes.index(actual_class)
                    predicted_idx = self.classes.index(predicted_class)
                    
                    all_labels.append(actual_idx)
                    all_preds.append(predicted_idx)
            
            if not all_labels:
                logger.warning("No valid labels found for performance analysis")
                return
            
            # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
            from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
            
            precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)
            recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)
            f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=0)
            
            # í´ë˜ìŠ¤ë³„ ìƒì„¸ ë©”íŠ¸ë¦­
            class_precision = precision_score(all_labels, all_preds, average=None, zero_division=0)
            class_recall = recall_score(all_labels, all_preds, average=None, zero_division=0)
            class_f1 = f1_score(all_labels, all_preds, average=None, zero_division=0)
            
            # Confusion Matrix ìƒì„±
            cm = confusion_matrix(all_labels, all_preds)
            
            # ê²°ê³¼ ì¶œë ¥
            logger.info("=" * 60)
            logger.info("PREDICTION PERFORMANCE ANALYSIS")
            logger.info("=" * 60)
            logger.info(f"Overall Metrics:")
            logger.info(f"  Precision: {precision:.4f}")
            logger.info(f"  Recall: {recall:.4f}")
            logger.info(f"  F1-Score: {f1:.4f}")
            logger.info("")
            logger.info("Class-wise Metrics:")
            for i, class_name in enumerate(self.classes):
                logger.info(f"  {class_name}:")
                logger.info(f"    Precision: {class_precision[i]:.4f}")
                logger.info(f"    Recall: {class_recall[i]:.4f}")
                logger.info(f"    F1-Score: {class_f1[i]:.4f}")
            logger.info("=" * 60)
            
            # ë©”íŠ¸ë¦­ì„ TXT íŒŒì¼ë¡œ ì €ì¥
            self.save_prediction_metrics_to_txt(cm, class_precision, class_recall, class_f1, precision, recall, f1)
            
            # Confusion Matrix ì‹œê°í™” ë° ì €ì¥
            self.save_prediction_confusion_matrix(cm, self.classes)
            
            logger.info("Prediction performance analysis completed!")
            
        except Exception as e:
            logger.error(f"Failed to analyze prediction performance: {e}")
    
    def _extract_class_from_path(self, image_path, dataset_path):
        """ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ ì‹¤ì œ í´ë˜ìŠ¤ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        try:
            # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
            abs_image_path = os.path.abspath(image_path)
            abs_dataset_path = os.path.abspath(dataset_path)
            
            # ë°ì´í„°ì…‹ ê²½ë¡œë¥¼ ì œê±°í•˜ì—¬ ìƒëŒ€ ê²½ë¡œ ì–»ê¸°
            if abs_image_path.startswith(abs_dataset_path):
                relative_path = abs_image_path[len(abs_dataset_path):].lstrip(os.sep)
                # ì²« ë²ˆì§¸ ë””ë ‰í† ë¦¬ê°€ í´ë˜ìŠ¤ëª…
                class_name = relative_path.split(os.sep)[0]
                return class_name
            
            return None
        except Exception as e:
            logger.warning(f"Failed to extract class from path {image_path}: {e}")
            return None
    
    def save_prediction_metrics_to_txt(self, cm, class_precision, class_recall, class_f1, overall_precision, overall_recall, overall_f1):
        """ì˜ˆì¸¡ ë©”íŠ¸ë¦­ì„ TXT íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            metrics_path = os.path.join(self.config['OUTPUT_DIR'], 'prediction_metrics.txt')
            
            with open(metrics_path, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write("WAFER DEFECT DETECTION - PREDICTION PERFORMANCE METRICS\n")
                f.write("=" * 80 + "\n\n")
                
                # ì „ì²´ ë©”íŠ¸ë¦­
                f.write("OVERALL METRICS:\n")
                f.write("-" * 40 + "\n")
                f.write(f"Precision: {overall_precision:.4f}\n")
                f.write(f"Recall: {overall_recall:.4f}\n")
                f.write(f"F1-Score: {overall_f1:.4f}\n\n")
                
                # í´ë˜ìŠ¤ë³„ ë©”íŠ¸ë¦­
                f.write("CLASS-WISE METRICS:\n")
                f.write("-" * 40 + "\n")
                f.write(f"{'Class':<20} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Correct':<10} {'Total':<10}\n")
                f.write("-" * 80 + "\n")
                
                for i, class_name in enumerate(self.classes):
                    # Confusion Matrixì—ì„œ TP, FP, FN ê³„ì‚°
                    tp = cm[i, i]
                    fp = cm[:, i].sum() - tp
                    fn = cm[i, :].sum() - tp
                    total = cm[i, :].sum()
                    
                    f.write(f"{class_name:<20} {class_precision[i]:<12.4f} {class_recall[i]:<12.4f} {class_f1[i]:<12.4f} {tp:<10} {total:<10}\n")
                
                f.write("\n" + "=" * 80 + "\n")
                f.write("CONFUSION MATRIX:\n")
                f.write("-" * 40 + "\n")
                
                # Confusion Matrix ì¶œë ¥
                f.write(f"{'':<15}")
                for class_name in self.classes:
                    f.write(f"{class_name:<10}")
                f.write("\n")
                
                for i, class_name in enumerate(self.classes):
                    f.write(f"{class_name:<15}")
                    for j in range(len(self.classes)):
                        f.write(f"{cm[i, j]:<10}")
                    f.write("\n")
                
                f.write("\n" + "=" * 80 + "\n")
                f.write("CONFIGURATION:\n")
                f.write("-" * 40 + "\n")
                f.write(f"Precision Threshold: {self.config['PRECISION_THRESHOLD']}\n")
                f.write(f"Confidence Threshold: {self.config['CONFIDENCE_THRESHOLD']}\n")
                f.write(f"Mapping Threshold: {self.config['MAPPING_THRESHOLD']}\n")
                f.write(f"Mapping Ratio Threshold: {self.config['MAPPING_RATIO_THRESHOLD']}\n")
            
            logger.info(f"Prediction metrics saved to: {metrics_path}")
            
        except Exception as e:
            logger.error(f"Failed to save prediction metrics to TXT: {e}")
    
    def save_prediction_confusion_matrix(self, cm, class_names):
        """ì˜ˆì¸¡ ê²°ê³¼ ê¸°ë°˜ Confusion Matrixë¥¼ ì‹œê°í™”í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            import matplotlib.pyplot as plt
            import seaborn as sns
            
            # Confusion Matrix ì‹œê°í™”
            plt.figure(figsize=(12, 10))
            
            # Confusion Matrixë§Œ í‘œì‹œ
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                       xticklabels=class_names, yticklabels=class_names)
            plt.title('Prediction Confusion Matrix', fontsize=16, fontweight='bold')
            plt.xlabel('Predicted', fontsize=12)
            plt.ylabel('Actual', fontsize=12)
            plt.xticks(rotation=45, ha='right')
            plt.yticks(rotation=0)
            
            plt.tight_layout()
            
            # ì €ì¥
            cm_path = os.path.join(self.config['OUTPUT_DIR'], 'prediction_confusion_matrix.png')
            plt.savefig(cm_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            logger.info(f"Prediction confusion matrix saved to: {cm_path}")
            
        except Exception as e:
            logger.error(f"Failed to save prediction confusion matrix: {e}")
    
    def learn_roi_patterns(self):
        """ëª¨ë“  í´ë˜ìŠ¤ì— ëŒ€í•´ ROI íŒ¨í„´ì„ í•™ìŠµí•©ë‹ˆë‹¤."""
        try:
            logger.info(f"Learning ROI patterns for {len(self.classes)} classes...")
            
            for class_name in self.classes:
                class_dir = os.path.join(self.config['DATASET_ROOT'], class_name)
                if not os.path.exists(class_dir):
                    logger.warning(f"Class directory not found: {class_dir}")
                    continue
                
                # í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ ì œí•œ
                max_samples = self.config['processing']['max_roi_samples']
                image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
                image_files = image_files[:max_samples]
                
                if not image_files:
                    logger.warning(f"No images found for class {class_name}")
                    continue
                
                class_idx = self.classes.index(class_name)
                roi_patterns = []
                
                for image_file in image_files:
                    try:
                        img_path = os.path.join(class_dir, image_file)
                        image = Image.open(img_path).convert('RGB')
                        
                        # GradCAMìœ¼ë¡œ ROI ì¶”ì¶œ
                        transform = transforms.Compose([
                            transforms.Resize((224, 224)),
                            transforms.ToTensor(),
                            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
                        ])
                        input_tensor = transform(image).unsqueeze(0)
                        
                        heatmap = self.gradcam_analyzer.generate_gradcam(input_tensor, class_idx)
                        roi_coords = extract_roi_from_heatmap(heatmap)
                        
                        roi_patterns.append({
                            'x1': roi_coords[0],
                            'y1': roi_coords[1], 
                            'x2': roi_coords[2],
                            'y2': roi_coords[3]
                        })
                        
                    except Exception as e:
                        logger.warning(f"Failed to process {image_file}: {e}")
                        continue
                
                if roi_patterns:
                    # ROI ì¢Œí‘œ í‰ê·  ê³„ì‚°
                    avg_roi = {
                        'x1': sum(r['x1'] for r in roi_patterns) / len(roi_patterns),
                        'y1': sum(r['y1'] for r in roi_patterns) / len(roi_patterns),
                        'x2': sum(r['x2'] for r in roi_patterns) / len(roi_patterns),
                        'y2': sum(r['y2'] for r in roi_patterns) / len(roi_patterns)
                    }
                    self.roi_patterns[class_name] = avg_roi
                    logger.info(f"{class_name}: ROI learned from {len(roi_patterns)} samples")
                else:
                    logger.warning(f"No valid ROI patterns found for {class_name}")
            
            logger.info(f"ROI patterns learned for {len(self.roi_patterns)} classes")
            
        except Exception as e:
            logger.error(f"ROI pattern learning failed: {str(e)}")
            raise WaferDetectorError(f"ROI pattern learning failed: {str(e)}")
    
    def create_mapping(self):
        """ëª¨ë“  í´ë˜ìŠ¤ì— ëŒ€í•´ GradCAM attention ì˜ì—­ì—ì„œ ê°ì²´ ë§¤í•‘ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            logger.info("Creating object mappings from GradCAM attention regions...")
            
            # í´ë˜ìŠ¤ë³„ ê°ì²´ ì¹´ìš´íŠ¸ ìˆ˜ì§‘
            class_object_counts = {class_name: {} for class_name in self.classes}
            
            for class_name in self.classes:
                class_dir = os.path.join(self.config['DATASET_ROOT'], class_name)
                if not os.path.exists(class_dir):
                    logger.warning(f"Class directory not found: {class_dir}")
                    continue
                
                # í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ ì œí•œ
                max_samples = self.config['processing']['max_mapping_samples']
                image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
                image_files = image_files[:max_samples]
                
                if not image_files:
                    logger.warning(f"No images found for {class_name}")
                    continue
                
                class_idx = self.classes.index(class_name)
                processed_count = 0
                
                for image_file in image_files:
                    try:
                        img_path = os.path.join(class_dir, image_file)
                        image = Image.open(img_path).convert('RGB')
                        
                        # GradCAMìœ¼ë¡œ attention ì˜ì—­ ì¶”ì¶œ
                        transform = transforms.Compose([
                            transforms.Resize((224, 224)),
                            transforms.ToTensor(),
                            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
                        ])
                        input_tensor = transform(image).unsqueeze(0)
                        
                        heatmap = self.gradcam_analyzer.generate_gradcam(input_tensor, class_idx)
                        roi_coords = extract_roi_from_heatmap(heatmap)
                        
                        # ROI ì˜ì—­ì—ì„œ ê°ì²´ ê²€ì¶œ
                        w, h = image.size
                        x1 = max(0, int(roi_coords[0] * w))
                        y1 = max(0, int(roi_coords[1] * h))
                        x2 = min(w, int(roi_coords[2] * w))
                        y2 = min(h, int(roi_coords[3] * h))
                        
                        if x2 > x1 and y2 > y1:
                            roi_image = image.crop((x1, y1, x2, y2))
                            results = self.yolo_model(roi_image, verbose=False)
                            
                            # ê²€ì¶œëœ ê°ì²´ ì¹´ìš´íŠ¸
                            for result in results:
                                if result.boxes is not None:
                                    for box in result.boxes:
                                        if box.conf > self.config['MAPPING_THRESHOLD']:
                                            obj_class = int(box.cls.item())
                                            obj_name = self.yolo_model.names[obj_class]
                                            
                                            if obj_name not in class_object_counts[class_name]:
                                                class_object_counts[class_name][obj_name] = 0
                                            class_object_counts[class_name][obj_name] += 1
                        
                        processed_count += 1
                        
                    except Exception as e:
                        logger.warning(f"Failed to process {image_file}: {e}")
                        continue
                
                logger.info(f"Processed {processed_count} samples for {class_name}")
            
            # ë§¤í•‘ ìƒì„± (ë¹„ìœ¨ ê¸°ë°˜)
            mapping_created = 0
            for class_name, obj_counts in class_object_counts.items():
                if obj_counts:
                    total_detections = sum(obj_counts.values())
                    best_obj, count = max(obj_counts.items(), key=lambda x: x[1])
                    ratio = count / total_detections
                    
                    # ë¹„ìœ¨ì´ ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ë§Œ ë§¤í•‘
                    if ratio >= self.config['MAPPING_RATIO_THRESHOLD']:
                        self.class_object_mapping[class_name] = best_obj
                        mapping_created += 1
                        logger.info(f"{class_name} -> {best_obj} (ratio: {ratio:.2f}, count: {count}/{total_detections})")
                    else:
                        logger.warning(f"Low ratio mapping for {class_name}: {ratio:.2f} < {self.config['MAPPING_RATIO_THRESHOLD']}")
                else:
                    # ê°ì²´ê°€ ê²€ì¶œë˜ì§€ ì•Šì•˜ì„ ë•Œ ëœë¤ ë§¤í•‘ ìƒì„±
                    import random
                    available_objects = list(self.yolo_model.names.values())
                    if available_objects:
                        random_obj = random.choice(available_objects)
                        self.class_object_mapping[class_name] = random_obj
                        mapping_created += 1
                        logger.info(f"{class_name} -> {random_obj} (random assignment - no objects detected)")
                    else:
                        logger.warning(f"No available objects for {class_name}")
            
            logger.info(f"Created {mapping_created} mappings")
            
        except Exception as e:
            logger.error(f"Failed to create mappings: {e}")
            raise
    
    def predict_image(self, image_path: Union[str, Path]) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            
        Raises:
            WaferDetectorError: ì˜ˆì¸¡ ì‹¤íŒ¨ì‹œ
        """
        try:
            if not self.classes:
                raise WaferDetectorError("Classes not loaded. Call load_classes() first.")
            if self.classification_model is None:
                raise WaferDetectorError("Classification model not loaded")
                
            image_path = Path(image_path)
            if not image_path.exists():
                raise WaferDetectorError(f"Image not found: {image_path}")
            
            # ê¸°ë³¸ ë¶„ë¥˜
            image = Image.open(image_path).convert('RGB')
            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            with torch.no_grad():
                outputs = self.classification_model(input_tensor)
                probabilities = torch.softmax(outputs, dim=1).cpu().numpy()[0]
                predicted_idx = np.argmax(probabilities)
                confidence = float(probabilities[predicted_idx])
                
                # ëª¨ë¸ì˜ í´ë˜ìŠ¤ ìˆ˜ì™€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ìˆ˜ê°€ ë‹¤ë¥¼ ë•Œ ì²˜ë¦¬
                if predicted_idx >= len(self.classes):
                    logger.warning(f"Predicted class index {predicted_idx} exceeds dataset classes {len(self.classes)}")
                    # ëª¨ë¸ì˜ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¥¼ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë¡œ ë§¤í•‘
                    predicted_idx = predicted_idx % len(self.classes)
                
                predicted_class = self.classes[predicted_idx]
            
            # ROI Enhanced ì˜ˆì¸¡ (ì‹ ë¢°ë„ê°€ ë‚®ê³  ì–´ë ¤ìš´ í´ë˜ìŠ¤ì¸ ê²½ìš°)
            if confidence < self.config['CONFIDENCE_THRESHOLD'] and predicted_class in self.difficult_classes:
                logger.info(f"Low confidence prediction ({confidence:.3f}) for difficult class {predicted_class}")
                
                # ROI ì˜ì—­ì—ì„œ ê°ì²´ ê²€ì¶œ
                roi_objects = self._detect_objects_in_roi(image, predicted_class)
                
                # ê°ì²´ ê²€ì¶œ ì‹¤íŒ¨ ì‹œ ì›ë˜ classification ê²°ê³¼ ë°˜í™˜
                if not roi_objects:
                    logger.info(f"No objects detected in ROI, returning original classification: {predicted_class}")
                    return {
                        'image_path': str(image_path),
                        'predicted_class': predicted_class,
                        'confidence': confidence,
                        'method': 'classification',
                        'detected_object': None,
                        'roi_objects': []
                    }
                
                # ë§¤í•‘ëœ ê°ì²´ì™€ ë¹„êµ
                if predicted_class in self.class_object_mapping:
                    mapped_object = self.class_object_mapping[predicted_class]
                    if mapped_object in roi_objects:
                        logger.info(f"ROI Enhanced: {predicted_class} -> {mapped_object} (confidence: {confidence:.3f})")
                        return {
                            'image_path': str(image_path),
                            'predicted_class': predicted_class,
                            'confidence': confidence,
                            'method': 'roi_enhanced',
                            'detected_object': mapped_object,
                            'roi_objects': roi_objects
                        }
                    else:
                        # ê²€ì¶œëœ ê°ì²´ì— ë”°ë¼ ë‹¤ë¥¸ í´ë˜ìŠ¤ë¡œ ì˜ˆì¸¡ ë³€ê²½
                        for detected_obj in roi_objects:
                            for class_name, mapped_obj in self.class_object_mapping.items():
                                if detected_obj == mapped_obj:
                                    logger.info(f"ROI Enhanced: {predicted_class} -> {class_name} (via {detected_obj}) (confidence: {confidence:.3f})")
                                    return {
                                        'image_path': str(image_path),
                                        'predicted_class': class_name, # ì˜ˆì¸¡ í´ë˜ìŠ¤ë¥¼ ë³€ê²½
                                        'confidence': confidence,
                                        'method': 'roi_enhanced',
                                        'detected_object': detected_obj,
                                        'roi_objects': roi_objects
                                    }
                
                # ë§¤í•‘ í…Œì´ë¸”ì— í•´ë‹¹ í´ë˜ìŠ¤ê°€ ì—†ê±°ë‚˜ ë§¤í•‘ëœ ê°ì²´ê°€ ì—†ëŠ” ê²½ìš° ì›ë˜ ê²°ê³¼ ë°˜í™˜
                logger.info(f"No matching mapping found, returning original classification: {predicted_class}")
                return {
                    'image_path': str(image_path),
                    'predicted_class': predicted_class,
                    'confidence': confidence,
                    'method': 'classification',
                    'detected_object': None,
                    'roi_objects': roi_objects
                }
            
            return {
                'image_path': str(image_path),
                'predicted_class': predicted_class,
                'confidence': confidence,
                'method': 'classification_only'
            }
            
        except Exception as e:
            raise WaferDetectorError(f"Image prediction failed: {str(e)}")
    
    def load_results(self, output_dir: Union[str, Path]) -> None:
        """
        ì €ì¥ëœ ê²°ê³¼ ë¡œë“œ
        
        Args:
            output_dir: ê²°ê³¼ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            
        Raises:
            WaferDetectorError: ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨ì‹œ
        """
        try:
            output_dir = Path(output_dir)
            
            # ROI íŒ¨í„´ ë¡œë“œ
            roi_path = output_dir / 'roi_patterns.json'
            if roi_path.exists():
                with open(roi_path, 'r') as f:
                    self.roi_patterns = json.load(f)
                logger.info(f"Loaded ROI patterns for {len(self.roi_patterns)} classes")
            
            # í´ë˜ìŠ¤ ë§¤í•‘ ë¡œë“œ
            mapping_path = output_dir / 'class_mapping.json'
            if mapping_path.exists():
                with open(mapping_path, 'r') as f:
                    mapping_data = json.load(f)
                    self.difficult_classes = mapping_data.get('difficult_classes', [])
                    self.class_object_mapping = mapping_data.get('class_object_mapping', {})
                logger.info(f"Loaded mappings for {len(self.class_object_mapping)} classes")
                
        except Exception as e:
            raise WaferDetectorError(f"Failed to load results: {str(e)}")
    
    def save_results(self, output_dir: Union[str, Path]) -> None:
        """
        ê²°ê³¼ ì €ì¥
        
        Args:
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            
        Raises:
            WaferDetectorError: ì €ì¥ ì‹¤íŒ¨ì‹œ
        """
        try:
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            
            # ROI íŒ¨í„´ ì €ì¥
            roi_file = output_path / 'roi_patterns.json'
            with open(roi_file, 'w') as f:
                json.dump(self.roi_patterns, f, indent=2)
            
            # í´ë˜ìŠ¤ ë§¤í•‘ ì €ì¥
            mapping_data = {
                'difficult_classes': self.difficult_classes,
                'class_object_mapping': self.class_object_mapping,
                'precision_scores': self.precision_scores.tolist() if self.precision_scores is not None else None,
                'f1_scores': self.f1_scores.tolist() if self.f1_scores is not None else None,
                'config': self.config
            }
            mapping_file = output_path / 'class_mapping.json'
            with open(mapping_file, 'w') as f:
                json.dump(mapping_data, f, indent=2)
            
            logger.info(f"Results saved to {output_path}")
            
        except Exception as e:
            raise WaferDetectorError(f"Failed to save results: {str(e)}")
    
    def get_stats(self) -> Dict[str, Any]:
        """
        í˜„ì¬ ìƒíƒœ í†µê³„ ë°˜í™˜
        
        Returns:
            í†µê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        return {
            'total_classes': len(self.classes),
            'difficult_classes': len(self.difficult_classes),
            'roi_patterns': len(self.roi_patterns),
            'class_mappings': len(self.class_object_mapping),
            'device': str(self.device),
            'models_loaded': {
                'classification': self.classification_model is not None,
                'yolo': self.yolo_model is not None,
                'gradcam': self.gradcam_analyzer is not None
            }
        }

    def save_confusion_matrix(self, cm, class_names):
        """Confusion Matrixë¥¼ ì‹œê°í™”í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            import matplotlib.pyplot as plt
            import seaborn as sns
            
            # Confusion Matrix ì‹œê°í™”
            plt.figure(figsize=(12, 10))
            
            # Confusion Matrixë§Œ í‘œì‹œ
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                       xticklabels=class_names, yticklabels=class_names)
            plt.title('Confusion Matrix', fontsize=16, fontweight='bold')
            plt.xlabel('Predicted', fontsize=12)
            plt.ylabel('Actual', fontsize=12)
            plt.xticks(rotation=45, ha='right')
            plt.yticks(rotation=0)
            
            plt.tight_layout()
            
            # ì €ì¥
            cm_path = os.path.join(self.config['OUTPUT_DIR'], 'confusion_matrix.png')
            plt.savefig(cm_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            logger.info(f"Confusion matrix saved to: {cm_path}")
            
        except Exception as e:
            logger.error(f"Failed to save confusion matrix: {e}")

    def _detect_objects_in_roi(self, image, predicted_class):
        """ROI ì˜ì—­ì—ì„œ ê°ì²´ë¥¼ ê²€ì¶œí•©ë‹ˆë‹¤."""
        try:
            if predicted_class not in self.roi_patterns:
                logger.warning(f"No ROI pattern for {predicted_class}")
                return []
            
            # ROI ì¢Œí‘œ ê³„ì‚°
            w, h = image.size
            roi = self.roi_patterns[predicted_class]
            
            x1 = max(0, int(roi['x1'] * w))
            y1 = max(0, int(roi['y1'] * h))
            x2 = min(w, int(roi['x2'] * w))
            y2 = min(h, int(roi['y2'] * h))
            
            if x2 <= x1 or y2 <= y1:
                logger.warning(f"Invalid ROI coordinates: {roi}")
                return []
            
            # ROI ì´ë¯¸ì§€ ì¶”ì¶œ ë° YOLO ê²€ì¶œ
            roi_image = image.crop((x1, y1, x2, y2)).resize(
                (self.config['YOLO_SIZE'], self.config['YOLO_SIZE'])
            )
            yolo_results = self.yolo_model(np.array(roi_image), verbose=False)
            
            detected_objects = []
            if len(yolo_results) > 0 and len(yolo_results[0].boxes) > 0:
                confidences = yolo_results[0].boxes.conf.cpu().numpy()
                classes = yolo_results[0].boxes.cls.cpu().numpy()
                
                for conf, cls in zip(confidences, classes):
                    if conf > self.config['processing']['yolo_confidence_threshold']:
                        obj_name = self.yolo_model.names[int(cls)]
                        detected_objects.append(obj_name)
                
                logger.info(f"Detected objects in ROI: {detected_objects}")
            else:
                logger.info("No objects detected in ROI")
            
            return detected_objects
            
        except Exception as e:
            logger.warning(f"ROI object detection failed: {str(e)}")
            return []

    def save_metrics_to_txt(self, cm, class_precision, class_recall, class_f1, overall_precision, overall_recall, overall_f1):
        """ë©”íŠ¸ë¦­ì„ TXT íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            metrics_path = os.path.join(self.config['OUTPUT_DIR'], 'performance_metrics.txt')
            
            with open(metrics_path, 'w', encoding='utf-8') as f:
                f.write("=" * 80 + "\n")
                f.write("WAFER DEFECT DETECTION - PERFORMANCE METRICS\n")
                f.write("=" * 80 + "\n\n")
                
                # ì „ì²´ ë©”íŠ¸ë¦­
                f.write("OVERALL METRICS:\n")
                f.write("-" * 40 + "\n")
                f.write(f"Precision: {overall_precision:.4f}\n")
                f.write(f"Recall: {overall_recall:.4f}\n")
                f.write(f"F1-Score: {overall_f1:.4f}\n\n")
                
                # í´ë˜ìŠ¤ë³„ ë©”íŠ¸ë¦­
                f.write("CLASS-WISE METRICS:\n")
                f.write("-" * 40 + "\n")
                f.write(f"{'Class':<20} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'Correct':<10} {'Total':<10}\n")
                f.write("-" * 80 + "\n")
                
                for i, class_name in enumerate(self.classes):
                    # Confusion Matrixì—ì„œ TP, FP, FN ê³„ì‚°
                    tp = cm[i, i]
                    fp = cm[:, i].sum() - tp
                    fn = cm[i, :].sum() - tp
                    total = cm[i, :].sum()
                    
                    f.write(f"{class_name:<20} {class_precision[i]:<12.4f} {class_recall[i]:<12.4f} {class_f1[i]:<12.4f} {tp:<10} {total:<10}\n")
                
                f.write("\n" + "=" * 80 + "\n")
                f.write("CONFUSION MATRIX:\n")
                f.write("-" * 40 + "\n")
                
                # Confusion Matrix ì¶œë ¥
                f.write(f"{'':<15}")
                for class_name in self.classes:
                    f.write(f"{class_name:<10}")
                f.write("\n")
                
                for i, class_name in enumerate(self.classes):
                    f.write(f"{class_name:<15}")
                    for j in range(len(self.classes)):
                        f.write(f"{cm[i, j]:<10}")
                    f.write("\n")
                
                f.write("\n" + "=" * 80 + "\n")
                f.write("DIFFICULT CLASSES:\n")
                f.write("-" * 40 + "\n")
                for class_name in self.difficult_classes:
                    f.write(f"- {class_name}\n")
                
                f.write("\n" + "=" * 80 + "\n")
                f.write("CONFIGURATION:\n")
                f.write("-" * 40 + "\n")
                f.write(f"Precision Threshold: {self.config['PRECISION_THRESHOLD']}\n")
                f.write(f"Confidence Threshold: {self.config['CONFIDENCE_THRESHOLD']}\n")
                f.write(f"Mapping Threshold: {self.config['MAPPING_THRESHOLD']}\n")
                f.write(f"Mapping Ratio Threshold: {self.config['MAPPING_RATIO_THRESHOLD']}\n")
            
            logger.info(f"Performance metrics saved to: {metrics_path}")
            
        except Exception as e:
            logger.error(f"Failed to save metrics to TXT: {e}")
