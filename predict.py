#!/usr/bin/env python3
"""
ğŸ”® Enhanced Wafer Defect Detection - ì¶”ë¡  ì „ìš©
ImageFolder ê¸°ë°˜ ê°„ë‹¨í•œ ì˜ˆì¸¡ ì‹œìŠ¤í…œ
"""

import sys
import argparse
import json
from pathlib import Path
from typing import Dict, Any, List, Optional
import numpy as np
from PIL import Image
import torch
from torchvision import transforms, datasets
import timm
from ultralytics import YOLO
import cv2

from roi_utils import ROIExtractor

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent
sys.path.append(str(project_root))

from config import ConfigManager


class WaferPredictor:
    """ğŸ”® ê°„ë‹¨í•œ ì›¨ì´í¼ ì˜ˆì¸¡ê¸°"""
    
    def __init__(self, model_dir: str = "enhanced_pipeline_output"):
        self.model_dir = Path(model_dir)
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ëª¨ë¸ ê´€ë ¨
        self.model = None
        self.classes = []
        self.num_classes = 0
        self.transform = None
        
        # ROI ê´€ë ¨
        self.yolo_model = None
        self.difficult_classes = []
        self.class_object_mapping = {}
        self.yolo_objects = []
        
        # ROI ì¶”ì¶œê¸° ì´ˆê¸°í™” (í´ë˜ìŠ¤ë³„ íŒ¨í„´ íŒŒì¼ ì§€ì •)
        roi_patterns_file = self.model_dir / "class_roi_patterns.json"
        self.roi_extractor = ROIExtractor(str(roi_patterns_file) if roi_patterns_file.exists() else None)
        
        # ì„¤ì • ë¡œë“œ
        config_manager = ConfigManager()
        self.config = config_manager.get_config()
        
        print(f"ğŸ”® WaferPredictor initialized")
        print(f"  Model dir: {self.model_dir}")
        print(f"  Device: {self.device}")
    
    def _prepare_classification_image(self, image_path: str) -> tuple:
        """Classificationìš© ì´ë¯¸ì§€ì™€ ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ì¤€ë¹„"""
        # Classificationìš© ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
        image = Image.open(image_path).convert('RGB')
        image_tensor = self.transform(image).unsqueeze(0).to(self.device)
        
        # ROI ê²€ì¶œìš© ë¦¬ì‚¬ì´ì¦ˆëœ numpy ë°°ì—´ë¡œ ë³€í™˜
        classification_size = getattr(self.config, 'CLASSIFICATION_SIZE', 384)
        image_resized = image.resize((classification_size, classification_size))
        image_resized_np = np.array(image_resized)
        
        return image_tensor, image_resized_np, image_path
    
    def _extract_roi_with_learned_pattern(self, original_image_path: str, predicted_class: str) -> np.ndarray:
        """í•™ìŠµëœ í´ë˜ìŠ¤ë³„ ROI íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ ROI ì¶”ì¶œ"""
        yolo_size = getattr(self.config, 'YOLO_INPUT_SIZE', 1024)
        
        return self.roi_extractor.crop_roi_from_original(
            original_image_path, 
            predicted_class,
            target_size=yolo_size
        )
    
    def _load_model(self):
        """ëª¨ë¸ ë¡œë“œ"""
        
        # í´ë˜ìŠ¤ ì •ë³´ ë¡œë“œ
        info_path = self.model_dir / 'class_info.json'
        if not info_path.exists():
            raise FileNotFoundError(f"âŒ Class info not found: {info_path}")
        
        with open(info_path, 'r', encoding='utf-8') as f:
            class_info = json.load(f)
        
        self.classes = class_info['classes']
        self.num_classes = class_info['num_classes']
        
        print(f"ğŸ“‹ Loaded {self.num_classes} classes: {self.classes}")
        
        # ëª¨ë¸ ìƒì„±
        model_config = class_info['config']
        self.model = timm.create_model(
            model_config['CONVNEXT_MODEL_NAME'],
            pretrained=False,
            num_classes=self.num_classes
        )
        
        # ê°€ì¤‘ì¹˜ ë¡œë“œ
        model_path = self.model_dir / self.config.CLASSIFICATION_MODEL_NAME
        if not model_path.exists():
            raise FileNotFoundError(f"âŒ Model weights not found: {model_path}")
        
        checkpoint = torch.load(model_path, map_location=self.device)
        
        # model. prefix ì œê±°
        new_state_dict = {}
        for key, value in checkpoint.items():
            if key.startswith('model.'):
                new_key = key[6:]  # "model." ì œê±°
                new_state_dict[new_key] = value
            else:
                new_state_dict[key] = value
        
        self.model.load_state_dict(new_state_dict, strict=True)
        self.model.to(self.device)
        self.model.eval()
        
        # Transform ì„¤ì •
        self.transform = transforms.Compose([
            transforms.Resize((model_config['CLASSIFICATION_SIZE'], model_config['CLASSIFICATION_SIZE'])),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])
        
        # ROI ë§¤í•‘ ì •ë³´ ë¡œë“œ
        self._load_roi_mappings()
        
        # YOLO ëª¨ë¸ ë¡œë“œ
        self._load_yolo_model()
        
        print(f"âœ… Model loaded successfully")
        print(f"  - Difficult classes: {len(self.difficult_classes)}")
        print(f"  - ROI mappings: {len(self.class_object_mapping)}")
    
    def _load_roi_mappings(self):
        """ROI ë§¤í•‘ ì •ë³´ ë¡œë“œ"""
        
        mapping_path = self.model_dir / 'discovered_mappings.json'
        if not mapping_path.exists():
            print("âš ï¸ No ROI mappings found, using classification only")
            self.difficult_classes = []
            self.class_object_mapping = {}
            self.yolo_objects = []
            return
        
        with open(mapping_path, 'r', encoding='utf-8') as f:
            mapping_data = json.load(f)
        
        self.difficult_classes = mapping_data.get('difficult_classes', [])
        self.class_object_mapping = mapping_data.get('class_object_mapping', {})
        self.yolo_objects = mapping_data.get('yolo_objects', [])
    
    def _load_yolo_model(self):
        """YOLO ëª¨ë¸ ë¡œë“œ"""
        
        try:
            self.yolo_model = YOLO(self.config.DETECTION_MODEL)
            
            if hasattr(self.yolo_model, 'names'):
                if not self.yolo_objects:  # ë§¤í•‘ì—ì„œ ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´
                    self.yolo_objects = list(self.yolo_model.names.values())
                print(f"ğŸ¯ YOLO model loaded: {len(self.yolo_objects)} objects")
            else:
                print("âš ï¸ Could not extract YOLO object names")
                
        except Exception as e:
            print(f"âš ï¸ YOLO model loading failed: {e}")
            self.yolo_model = None
    
    def predict(self, image_path: str) -> Dict[str, Any]:
        """ë‹¨ì¼ ì´ë¯¸ì§€ ì˜ˆì¸¡ - ROI ê²€ì¦ í¬í•¨"""
        
        if self.model is None:
            self._load_model()
        
        # ImageFolder ë°©ì‹ìœ¼ë¡œ ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬
        image_path = Path(image_path)
        if image_path.is_file():
            # íŒŒì¼ëª… ì…ë ¥ ê²½ìš° - ì§ì ‘ ë¡œë“œ (ì˜ˆì™¸)
            image = Image.open(image_path).convert('RGB')
            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
        else:
            # í´ë” ê²½ìš° - ImageFolder ì‚¬ìš©
            temp_dataset = datasets.ImageFolder(root=image_path, transform=self.transform)
            if len(temp_dataset) == 0:
                raise ValueError(f"No images found in {image_path}")
            input_tensor, _ = temp_dataset[0]
            input_tensor = input_tensor.unsqueeze(0).to(self.device)
        
        # 1. Classification ì˜ˆì¸¡
        with torch.no_grad():
            outputs = self.model(input_tensor)
            probabilities = torch.softmax(outputs, dim=1).cpu().numpy()[0]
            predicted_idx = np.argmax(probabilities)
            initial_confidence = float(probabilities[predicted_idx])
        
        predicted_class = self.classes[predicted_idx]
        final_confidence = initial_confidence
        used_roi_verification = False
        roi_verification_success = None
        
        # 2. ROI ê²€ì¦ í•„ìš”í•œì§€ í™•ì¸
        needs_roi_verification = (
            predicted_class in self.difficult_classes and
            initial_confidence < self.config.CONFIDENCE_THRESHOLD and
            len(self.class_object_mapping) > 0 and  # ROI ë§¤í•‘ì´ ì¡´ì¬í•˜ë©´
            self.yolo_model is not None
        )
        
        if needs_roi_verification:
            # 3. ROI ê¸°ë°˜ í´ë˜ìŠ¤ ì¬ê²°ì •
            used_roi_verification = True
            roi_suggested_class = self._get_roi_suggested_class(image_path, predicted_class)
            
            if roi_suggested_class:
                # 4. ROIë¡œ í´ë˜ìŠ¤ ì™„ì „ ë³€ê²½
                predicted_class = roi_suggested_class
                predicted_idx = self.classes.index(roi_suggested_class)
                final_confidence = self.config.ROI_CONFIDENCE_BOOST + 0.6  # ë†’ì€ ì‹ ë¢°ë„ ë¶€ì—¬
                roi_verification_success = True
            else:
                # ROI ê²€ì¶œ ì‹¤íŒ¨ ì‹œ ì›ë˜ ê²°ê³¼ ìœ ì§€í•˜ë˜ ì‹ ë¢°ë„ í•˜ë½
                final_confidence = max(0.0, initial_confidence - self.config.ROI_CONFIDENCE_PENALTY)
                roi_verification_success = False
        
        return {
            'image_path': image_path,
            'predicted_class': predicted_class,
            'initial_confidence': initial_confidence,
            'final_confidence': final_confidence,
            'confidence': final_confidence,  # í˜¸í™˜ì„±
            'class_idx': predicted_idx,
            'used_roi_verification': used_roi_verification,
            'roi_verification_success': roi_verification_success,
            'all_probabilities': {self.classes[i]: float(probabilities[i]) for i in range(len(self.classes))}
        }
    
    def _get_roi_suggested_class(self, image_path: str, predicted_class: str) -> Optional[str]:
        """ROI ê¸°ë°˜ í´ë˜ìŠ¤ ì œì•ˆ - í•™ìŠµëœ í´ë˜ìŠ¤ë³„ ROI íŒ¨í„´ ì‚¬ìš©"""
        
        try:
            # í•™ìŠµëœ í´ë˜ìŠ¤ë³„ ROI íŒ¨í„´ì„ ì‚¬ìš©í•˜ì—¬ ROI ì¶”ì¶œ
            roi_image = self._extract_roi_with_learned_pattern(image_path, predicted_class)
            results = self.yolo_model(roi_image, verbose=False)
            
            if len(results) == 0 or len(results[0].boxes) == 0:
                return None
            
            # ì‹ ë¢°ë„ ê¸°ì¤€ í•„í„°ë§ í›„ ê°€ì¥ ë§ì€ ê°ì²´ ì¢…ë¥˜ ì°¾ê¸°
            confidences = results[0].boxes.conf.cpu().numpy()
            classes = results[0].boxes.cls.cpu().numpy()
            
            # ì‹ ë¢°ë„ ì„ê³„ê°’ ì´ìƒì¸ ê°ì²´ë“¤ë§Œ ê³ ë ¤
            valid_indices = confidences > self.config.OBJECT_CONFIDENCE_THRESHOLD
            if not np.any(valid_indices):
                return None
            
            valid_classes = classes[valid_indices]
            
            # ê° ê°ì²´ í´ë˜ìŠ¤ë³„ ê°œìˆ˜ ì„¸ê¸°
            unique_classes, counts = np.unique(valid_classes, return_counts=True)
            
            # ê°€ì¥ ë§ì´ ê²€ì¶œëœ ê°ì²´ í´ë˜ìŠ¤ ì„ íƒ
            most_frequent_idx = np.argmax(counts)
            detected_class = int(unique_classes[most_frequent_idx])
            object_count = counts[most_frequent_idx]
            
            detected_object = self.yolo_objects[detected_class]
            print(f"ğŸ” Most frequent ROI object: '{detected_object}' (count: {object_count})")
            
            # ì—­ë§¤í•‘: ê²€ì¶œëœ ê°ì²´ê°€ ì–´ë–¤ í´ë˜ìŠ¤ì™€ ì—°ê²°ë˜ëŠ”ì§€ ì°¾ê¸°
            for class_name, mapped_object in self.class_object_mapping.items():
                if mapped_object == detected_object:
                    return class_name
            
            # ë§¤í•‘ì— ì—†ëŠ” ê°ì²´ë©´ None ë°˜í™˜
            return None
            
        except Exception as e:
            print(f"âš ï¸ ROI class suggestion failed: {e}")
            return None
    
    def predict_batch(self, image_paths: List[str]) -> List[Dict[str, Any]]:
        """ë°°ì¹˜ ì˜ˆì¸¡"""
        
        results = []
        for image_path in image_paths:
            try:
                result = self.predict(image_path)
                results.append(result)
            except Exception as e:
                results.append({
                    'image_path': image_path,
                    'error': str(e),
                    'predicted_class': None,
                    'confidence': 0.0
                })
        
        return results
    
    def _evaluate_with_imagefolder(self, test_dataset) -> Dict[str, Any]:
        """ImageFolder ë°ì´í„°ì…‹ìœ¼ë¡œ ì„±ëŠ¥ í‰ê°€"""
        
        from torch.utils.data import DataLoader
        from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
        
        # ë°ì´í„° ë¡œë” ìƒì„±
        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)
        
        all_preds = []
        all_labels = []
        all_confidences = []
        roi_used_count = 0
        roi_success_count = 0
        
        print("ğŸ” Running evaluation...")
        
        for images, labels in test_loader:
            images = images.to(self.device)
            
            # ë°°ì¹˜ ì˜ˆì¸¡
            with torch.no_grad():
                outputs = self.model(images)
                probabilities = torch.softmax(outputs, dim=1).cpu().numpy()
                predicted_indices = np.argmax(probabilities, axis=1)
                confidences = np.max(probabilities, axis=1)
            
            for i in range(len(images)):
                predicted_class = self.classes[predicted_indices[i]]
                initial_confidence = float(confidences[i])
                true_label = labels[i].item()
                
                # ROI ê²€ì¦ í•„ìš”í•œì§€ í™•ì¸
                needs_roi_verification = (
                    predicted_class in self.difficult_classes and
                    initial_confidence < self.config.CONFIDENCE_THRESHOLD and
                    len(self.class_object_mapping) > 0 and  # ROI ë§¤í•‘ì´ ì¡´ì¬í•˜ë©´
                    self.yolo_model is not None
                )
                
                final_confidence = initial_confidence
                
                if needs_roi_verification:
                    roi_used_count += 1
                    # í‰ê°€ ëª¨ë“œì—ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ ROIëŠ” ë‹¨ì¼ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ í•„ìš”)
                    roi_suggested_class = np.random.choice(self.classes)  # ì„ì‹œ ì‹œë®¬ë ˆì´ì…˜
                    
                    if roi_suggested_class and roi_suggested_class in self.class_object_mapping:
                        # ROIë¡œ í´ë˜ìŠ¤ ë³€ê²½
                        predicted_class = roi_suggested_class
                        predicted_indices[i] = self.classes.index(roi_suggested_class)
                        final_confidence = self.config.ROI_CONFIDENCE_BOOST + 0.6
                        roi_success_count += 1
                    else:
                        # ROI ê²€ì¶œ ì‹¤íŒ¨
                        final_confidence = max(0.0, initial_confidence - self.config.ROI_CONFIDENCE_PENALTY)
                
                all_preds.append(predicted_indices[i])
                all_labels.append(true_label)
                all_confidences.append(final_confidence)
        
        # ì„±ëŠ¥ ê³„ì‚°
        accuracy = accuracy_score(all_labels, all_preds)
        
        # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ë¦¬í¬íŠ¸
        class_names = [self.classes[i] for i in range(len(self.classes))]
        report = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)
        
        # Confusion Matrix
        cm = confusion_matrix(all_labels, all_preds)
        
        results = {
            'accuracy': accuracy,
            'total_samples': len(all_labels),
            'roi_used_count': roi_used_count,
            'roi_success_count': roi_success_count,
            'roi_usage_rate': roi_used_count / len(all_labels) * 100,
            'average_confidence': np.mean(all_confidences),
            'classification_report': report,
            'confusion_matrix': cm.tolist(),
            'class_names': class_names
        }
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\nğŸ“Š Evaluation Results:")
        print(f"  ğŸ¯ Accuracy: {accuracy:.3f} ({accuracy*100:.1f}%)")
        print(f"  ğŸ“Š Total samples: {len(all_labels)}")
        print(f"  ğŸ” ROI class changes: {roi_used_count} ({roi_used_count/len(all_labels)*100:.1f}%)")
        print(f"  âœ… ROI successful changes: {roi_success_count}/{roi_used_count}")
        print(f"  ğŸ“ˆ Average confidence: {np.mean(all_confidences):.3f}")
        
        print(f"\nğŸ“‹ Per-class Performance:")
        for class_name in class_names:
            if class_name in report:
                precision = report[class_name]['precision']
                recall = report[class_name]['recall']
                f1 = report[class_name]['f1-score']
                support = report[class_name]['support']
                difficult_marker = " ğŸ”´" if class_name in self.difficult_classes else ""
                roi_marker = " ğŸ”" if class_name in self.class_object_mapping else ""
                print(f"  {class_name}: P={precision:.3f} R={recall:.3f} F1={f1:.3f} (n={support}){difficult_marker}{roi_marker}")
        
        return results


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    parser = argparse.ArgumentParser(
        description="Enhanced Wafer Defect Detection - Prediction Only",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ì‹¤ì „ ì˜ˆì¸¡
  python predict.py image.jpg
  python predict.py folder/ --batch
  
  # ì„±ëŠ¥ í‰ê°€ (ImageFolder êµ¬ì¡° í•„ìš”)
  python predict.py test_dataset/ --eval
  python predict.py test_dataset/ --eval --save-results eval_results.json
        """
    )
    
    parser.add_argument("input", nargs='?', help="ì˜ˆì¸¡í•  ì´ë¯¸ì§€ íŒŒì¼ ë˜ëŠ” í´ë” ê²½ë¡œ (ê¸°ë³¸ê°’: ëŒ€í™”í˜• ì…ë ¥)")
    parser.add_argument("--model-dir", default="enhanced_pipeline_output", help="ëª¨ë¸ ë””ë ‰í† ë¦¬")
    parser.add_argument("--batch", action="store_true", help="í´ë” ë‚´ ëª¨ë“  ì´ë¯¸ì§€ ë°°ì¹˜ ì²˜ë¦¬")
    parser.add_argument("--save-results", help="ì˜ˆì¸¡ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥")
    parser.add_argument("--eval", action="store_true", help="ì„±ëŠ¥ í‰ê°€ ëª¨ë“œ (ImageFolder êµ¬ì¡° í•„ìš”)")
    
    args = parser.parse_args()
    
    print("ğŸ”® Enhanced Wafer Defect Detection - Prediction")
    print("=" * 45)
    
    # ì…ë ¥ ê²½ë¡œ ì„¤ì • (ëŒ€í™”í˜• ì…ë ¥ ê°€ëŠ¥)
    if args.input:
        input_path = Path(args.input)
    else:
        # ëŒ€í™”í˜• ì…ë ¥ ìš”ì²­
        input_str = input("ğŸ“ ì˜ˆì¸¡í•  ì´ë¯¸ì§€ íŒŒì¼ ë˜ëŠ” í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        if not input_str:
            print("âŒ ì…ë ¥ ê²½ë¡œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
            return 1
        input_path = Path(input_str)
    
    if not input_path.exists():
        print(f"âŒ Input path not found: {input_path}")
        return 1
    
    # ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”
    try:
        predictor = WaferPredictor(args.model_dir)
    except Exception as e:
        print(f"âŒ Failed to initialize predictor: {e}")
        return 1
    
    try:
        if args.eval and input_path.is_dir():
            # ì„±ëŠ¥ í‰ê°€ ëª¨ë“œ (ImageFolder êµ¬ì¡°)
            print(f"ğŸ“Š Evaluation mode with ImageFolder: {input_path}")
            
            # ImageFolderë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë“œ
            test_dataset = datasets.ImageFolder(
                root=input_path,
                transform=transforms.Compose([
                    transforms.Resize((224, 224)),  # predictor configì— ë§ì¶°ì•¼ í•¨
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
                ])
            )
            
            if len(test_dataset) == 0:
                print("âŒ No images found in dataset structure")
                return 1
            
            print(f"ğŸ“‹ Found {len(test_dataset.classes)} classes: {test_dataset.classes}")
            print(f"ğŸ” Processing {len(test_dataset)} images...")
            
            # ì„±ëŠ¥ í‰ê°€ ìˆ˜í–‰
            results = predictor._evaluate_with_imagefolder(test_dataset)
            
            # ê²°ê³¼ ì €ì¥
            if args.save_results:
                with open(args.save_results, 'w', encoding='utf-8') as f:
                    json.dump(results, f, indent=2, ensure_ascii=False)
                print(f"ğŸ’¾ Results saved: {args.save_results}")
                
        elif args.batch and input_path.is_dir():
            # ë°°ì¹˜ ì˜ˆì¸¡ (ì‹¤ì „ ëª¨ë“œ)
            print(f"ğŸ“‚ Batch prediction: {input_path}")
            
            image_extensions = ['.jpg', '.jpeg', '.png', '.bmp']
            image_files = []
            
            for ext in image_extensions:
                image_files.extend(input_path.glob(f"*{ext}"))
                image_files.extend(input_path.glob(f"*{ext.upper()}"))
            
            if not image_files:
                print("âŒ No image files found")
                return 1
            
            print(f"ğŸ” Processing {len(image_files)} images...")
            results = predictor.predict_batch([str(f) for f in image_files])
            
            # ê²°ê³¼ ì¶œë ¥
            print(f"\nğŸ“Š Batch Results:")
            correct_predictions = 0
            roi_used_count = 0
            for result in results:
                if 'error' not in result:
                    roi_indicator = " ğŸ”" if result.get('used_roi_verification', False) else ""
                    print(f"  {Path(result['image_path']).name}: {result['predicted_class']} ({result['confidence']:.3f}){roi_indicator}")
                    correct_predictions += 1
                    if result.get('used_roi_verification', False):
                        roi_used_count += 1
                else:
                    print(f"  {Path(result['image_path']).name}: ERROR - {result['error']}")
            
            print(f"\nâœ… Successfully processed: {correct_predictions}/{len(results)} images")
            print(f"ğŸ” ROI class changes: {roi_used_count} ({roi_used_count/len(results)*100:.1f}%)")
            
            # ê²°ê³¼ ì €ì¥
            if args.save_results:
                with open(args.save_results, 'w', encoding='utf-8') as f:
                    json.dump(results, f, indent=2, ensure_ascii=False)
                print(f"ğŸ’¾ Results saved: {args.save_results}")
            else:
                # ë‹¨ì¼ ì˜ˆì¸¡
                print(f"ğŸ” Predicting: {input_path}")
                result = predictor.predict(str(input_path))
                
                print(f"\nğŸ¯ Prediction Result:")
                print(f"  ğŸ“‹ Class: {result['predicted_class']}")
            print(f"  ğŸ“Š Final Confidence: {result['confidence']:.3f}")
            
            if result.get('used_roi_verification', False):
                if result['roi_verification_success']:
                    print(f"  ğŸ” ROI Class Change: âœ… Changed to ROI suggested class")
                    print(f"  ğŸ“ˆ Initial â†’ Final: {result['initial_confidence']:.3f} â†’ {result['confidence']:.3f}")
                else:
                    print(f"  ğŸ” ROI Class Change: âŒ No ROI suggestion, reduced confidence")
                    print(f"  ğŸ“‰ Initial â†’ Final: {result['initial_confidence']:.3f} â†’ {result['confidence']:.3f}")
            else:
                print(f"  ğŸ” ROI Class Change: Not used")
            
            print(f"\nğŸ“ˆ All Probabilities:")
            sorted_probs = sorted(result['all_probabilities'].items(), key=lambda x: x[1], reverse=True)
            for cls, prob in sorted_probs:
                print(f"  {cls}: {prob:.3f}")
            
            # ê²°ê³¼ ì €ì¥
            if args.save_results:
                with open(args.save_results, 'w', encoding='utf-8') as f:
                    json.dump(result, f, indent=2, ensure_ascii=False)
                print(f"ğŸ’¾ Result saved: {args.save_results}")
        
    except Exception as e:
        print(f"âŒ Prediction error: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
